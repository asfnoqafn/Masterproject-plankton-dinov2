{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lmdb\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "\n",
    "def image_to_byte_array(image: Image) -> bytes:\n",
    "    \"\"\"Convert a PIL image to a byte array.\"\"\"\n",
    "    img_byte_arr = BytesIO()\n",
    "    image.save(img_byte_arr, format='JPEG')\n",
    "    return img_byte_arr.getvalue()\n",
    "\n",
    "def create_separate_lmdbs(input_folder, output_folder):\n",
    "    # Convert available memory to bytes (193000 * 32 = 6,176,000 bytes)\n",
    "    available_memory = 193000 * 32  # in bytes\n",
    "\n",
    "    # Create the main folders for images and labels\n",
    "    img_lmdb_path = os.path.join(output_folder, \"train_imgs\", \"data.lmdb\")\n",
    "    label_lmdb_path = os.path.join(output_folder, \"train_labels\", \"data.lmdb\")\n",
    "    os.makedirs(os.path.dirname(img_lmdb_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(label_lmdb_path), exist_ok=True)\n",
    "\n",
    "    # Open two LMDB environments with the calculated map size\n",
    "    img_lmdb_env = lmdb.open(img_lmdb_path, map_size=available_memory)\n",
    "    label_lmdb_env = lmdb.open(label_lmdb_path, map_size=available_memory)\n",
    "\n",
    "    with img_lmdb_env.begin(write=True) as img_txn, label_lmdb_env.begin(write=True) as label_txn:\n",
    "        idx = 0\n",
    "        # Traverse through each class folder, assigning a label based on position\n",
    "        for label, class_name in enumerate(sorted(os.listdir(input_folder))):\n",
    "            class_path = os.path.join(input_folder, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            # Traverse through each image in the class folder\n",
    "            for img_name in sorted(os.listdir(class_path)):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                if not img_path.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    continue\n",
    "\n",
    "                # Load the image and convert it to bytes\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img_bytes = image_to_byte_array(img)\n",
    "\n",
    "                # Store image bytes in img_lmdb\n",
    "                img_txn.put(f\"{idx}\".encode(), img_bytes)\n",
    "                \n",
    "                # Store the label in label_lmdb\n",
    "                label_txn.put(f\"{idx}\".encode(), pickle.dumps(label))\n",
    "                \n",
    "                idx += 1\n",
    "\n",
    "    img_lmdb_env.close()\n",
    "    label_lmdb_env.close()\n",
    "    print(f\"Image LMDB file created at: {img_lmdb_path}\")\n",
    "    print(f\"Label LMDB file created at: {label_lmdb_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import psutil\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "\n",
    "def image_to_byte_array(image: Image) -> bytes:\n",
    "    \"\"\"Convert a PIL image to a byte array.\"\"\"\n",
    "    img_byte_arr = BytesIO()\n",
    "    image.save(img_byte_arr, format='JPEG')\n",
    "    return img_byte_arr.getvalue()\n",
    "\n",
    "def get_available_memory():\n",
    "    \"\"\"Get available memory and return a safe allocation size for LMDB.\"\"\"\n",
    "    available_memory = psutil.virtual_memory().available\n",
    "    print(f\"Available memory: {available_memory / 1024 / 1024} MB\")\n",
    "    return int(available_memory * 0.5)  # Use 50% of available memory as a safe map_size\n",
    "\n",
    "def create_separate_lmdbs_in_batches(input_folder, output_folder, batch_size=50000):\n",
    "    # Set available memory for LMDB map_size\n",
    "    map_size = get_available_memory()\n",
    "\n",
    "    idx = 0\n",
    "    batch_num = 0\n",
    "\n",
    "    # Traverse through each class folder, assigning a label based on position\n",
    "    for label, class_name in enumerate(sorted(os.listdir(input_folder))):\n",
    "        class_path = os.path.join(input_folder, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for img_name in sorted(os.listdir(class_path)):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            if not img_path.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "\n",
    "            # Load the image and convert it to bytes\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_bytes = image_to_byte_array(img)\n",
    "\n",
    "            # If starting a new batch, create new LMDB environments for images and labels\n",
    "            if idx % batch_size == 0:\n",
    "                if idx > 0:\n",
    "                    # Close previous batch LMDB files\n",
    "                    img_lmdb_env.close()\n",
    "                    label_lmdb_env.close()\n",
    "                    print(f\"Batch {batch_num} saved with images and labels.\")\n",
    "\n",
    "                # Define batch LMDB file paths\n",
    "                batch_start = idx\n",
    "                batch_end = idx + batch_size - 1\n",
    "                img_lmdb_path = os.path.join(output_folder, f\"img{batch_start}-{batch_end}_imgs\", \"data.lmdb\")\n",
    "                label_lmdb_path = os.path.join(output_folder, f\"img{batch_start}-{batch_end}_labels\", \"data.lmdb\")\n",
    "                os.makedirs(os.path.dirname(img_lmdb_path), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(label_lmdb_path), exist_ok=True)\n",
    "\n",
    "                # Open new LMDB environments for the current batch\n",
    "                img_lmdb_env = lmdb.open(img_lmdb_path, map_size=map_size)\n",
    "                label_lmdb_env = lmdb.open(label_lmdb_path, map_size=map_size)\n",
    "                batch_num += 1\n",
    "\n",
    "            # Store image bytes in img_lmdb and label in label_lmdb\n",
    "            with img_lmdb_env.begin(write=True) as img_txn, label_lmdb_env.begin(write=True) as label_txn:\n",
    "                img_txn.put(f\"{idx}\".encode(), img_bytes)\n",
    "                label_txn.put(f\"{idx}\".encode(), pickle.dumps(label))\n",
    "                \n",
    "            idx += 1\n",
    "\n",
    "    # Close the final batch\n",
    "    img_lmdb_env.close()\n",
    "    label_lmdb_env.close()\n",
    "    print(f\"Final batch {batch_num} saved with images and labels.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available memory: 494154.73828125 MB\n",
      "Final batch 1 saved with images and labels.\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/kaggle/train\"\n",
    "output_folder = \"/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/kaggle/train_lmdb\"\n",
    "create_separate_lmdbs_in_batches(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/run/eval/knn.py\", line 10, in <module>\n",
      "    from dinov2.eval.knn import get_args_parser\n",
      "ModuleNotFoundError: No module named 'dinov2'\n"
     ]
    }
   ],
   "source": [
    "!python Masterproject-plankton-dinov2/dinov2/run/eval/knn.py \\\n",
    "--config-file Masterproject-plankton-dinov2/dinov2/configs/eval/vits14_pretrain.yaml \\\n",
    "--pretrained-weights 'checkpoints/dinov2_vits14_pretrain.pth' --output-dir \\\n",
    "/home/hk-project-p0021769/hgf_grc7525/output/ \\\n",
    "--train-dataset='LMDBDataset:split=TEST:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/kaggle/train_lmdb:extra=*' \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnode\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'node' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
