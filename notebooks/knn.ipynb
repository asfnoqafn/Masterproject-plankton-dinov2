{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hkfs/home/project/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dinov2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m one_hot, softmax\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdinov2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     SamplerType,\n\u001b[1;32m     17\u001b[0m     make_data_loader,\n\u001b[1;32m     18\u001b[0m     make_dataset,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     make_classification_eval_transform,\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dinov2'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from functools import partial\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import one_hot, softmax\n",
    "\n",
    "import dinov2.distributed as distributed\n",
    "from dinov2.data import (\n",
    "    SamplerType,\n",
    "    make_data_loader,\n",
    "    make_dataset,\n",
    ")\n",
    "from dinov2.data.transforms import (\n",
    "    make_classification_eval_transform,\n",
    ")\n",
    "from dinov2.eval.metrics import (\n",
    "    AccuracyAveraging,\n",
    "    build_topk_accuracy_metric,\n",
    ")\n",
    "from dinov2.eval.setup import (\n",
    "    get_args_parser as get_setup_args_parser,\n",
    ")\n",
    "from dinov2.eval.setup import setup_and_build_model\n",
    "from dinov2.eval.utils import (\n",
    "    ModelWithNormalize,\n",
    "    evaluate,\n",
    "    extract_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "sys.path.append('/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/bin/python'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"dinov2\")\n",
    "\n",
    "\n",
    "def get_args_parser(\n",
    "    description: Optional[str] = None,\n",
    "    parents: Optional[List[argparse.ArgumentParser]] = None,\n",
    "    add_help: bool = True,\n",
    "):\n",
    "    parents = parents or []\n",
    "    setup_args_parser = get_setup_args_parser(parents=parents, add_help=False)\n",
    "    parents = [setup_args_parser]\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=description,\n",
    "        parents=parents,\n",
    "        add_help=add_help,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train-dataset\",\n",
    "        dest=\"train_dataset_str\",\n",
    "        type=str,\n",
    "        help=\"Training dataset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--val-dataset\",\n",
    "        dest=\"val_dataset_str\",\n",
    "        type=str,\n",
    "        help=\"Validation dataset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nb_knn\",\n",
    "        nargs=\"+\",\n",
    "        type=int,\n",
    "        help=\"Number of NN to use. 20 is usually working the best.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--temperature\",\n",
    "        type=float,\n",
    "        help=\"Temperature used in the voting coefficient\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gather-on-cpu\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Whether to gather the train features on cpu, slower\"\n",
    "        \"but useful to avoid OOM for large datasets (e.g. ImageNet22k).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch-size\",\n",
    "        type=int,\n",
    "        help=\"Batch size.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-workers\",\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help=\"Number of workers in DataLoader.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--n-per-class-list\",\n",
    "        nargs=\"+\",\n",
    "        type=int,\n",
    "        help=\"Number to take per class\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--n-tries\",\n",
    "        type=int,\n",
    "        help=\"Number of tries\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--run_name\",\n",
    "        type=str,\n",
    "        help=\"Name for the wandb log\",\n",
    "        default=\"knn_run\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_nodes\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Set number of nodes used.\",\n",
    "    )\n",
    "    parser.set_defaults(\n",
    "        train_dataset_str=\"ImageNet:split=TRAIN\",\n",
    "        val_dataset_str=\"ImageNet:split=VAL\",\n",
    "        nb_knn=[10, 20, 100, 200],\n",
    "        temperature=0.07,\n",
    "        batch_size=256,\n",
    "        n_per_class_list=[-1],\n",
    "        n_tries=1,\n",
    "    )\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Gets knn of test features from all processes on a chunk of the train features\n",
    "\n",
    "    Each rank gets a chunk of the train features as well as a chunk of the test features.\n",
    "    In `compute_neighbors`, for each rank one after the other, its chunk of test features\n",
    "    is sent to all devices, partial knns are computed with each chunk of train features\n",
    "    then collated back on the original device.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        nb_knn,\n",
    "        T,\n",
    "        device,\n",
    "        num_classes=1000,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.global_rank = distributed.get_global_rank()\n",
    "        self.global_size = distributed.get_global_size()\n",
    "\n",
    "        self.device = device\n",
    "        self.train_features_rank_T = train_features.chunk(self.global_size)[self.global_rank].T.to(self.device)\n",
    "        self.candidates = train_labels.chunk(self.global_size)[self.global_rank].view(1, -1).to(self.device)\n",
    "\n",
    "        self.nb_knn = nb_knn\n",
    "        self.max_k = max(self.nb_knn)\n",
    "        self.T = T\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def _get_knn_sims_and_labels(self, similarity, train_labels):\n",
    "        topk_sims, indices = similarity.topk(self.max_k, largest=True, sorted=True)\n",
    "        neighbors_labels = torch.gather(train_labels, 1, indices)\n",
    "        return topk_sims, neighbors_labels\n",
    "\n",
    "    def _similarity_for_rank(self, features_rank, source_rank):\n",
    "        # Send the features from `source_rank` to all ranks\n",
    "        broadcast_shape = torch.tensor(features_rank.shape).to(self.device)\n",
    "        torch.distributed.broadcast(broadcast_shape, source_rank)\n",
    "\n",
    "        broadcasted = features_rank\n",
    "        if self.global_rank != source_rank:\n",
    "            broadcasted = torch.zeros(\n",
    "                *broadcast_shape,\n",
    "                dtype=features_rank.dtype,\n",
    "                device=self.device,\n",
    "            )\n",
    "        torch.distributed.broadcast(broadcasted, source_rank)\n",
    "\n",
    "        # Compute the neighbors for `source_rank` among `train_features_rank_T`\n",
    "        similarity_rank = torch.mm(broadcasted, self.train_features_rank_T)\n",
    "        candidate_labels = self.candidates.expand(len(similarity_rank), -1)\n",
    "        return self._get_knn_sims_and_labels(similarity_rank, candidate_labels)\n",
    "\n",
    "    def _gather_all_knn_for_rank(self, topk_sims, neighbors_labels, target_rank):\n",
    "        # Gather all neighbors for `target_rank`\n",
    "        topk_sims_rank = retrieved_rank = None\n",
    "        if self.global_rank == target_rank:\n",
    "            topk_sims_rank = [torch.zeros_like(topk_sims) for _ in range(self.global_size)]\n",
    "            retrieved_rank = [torch.zeros_like(neighbors_labels) for _ in range(self.global_size)]\n",
    "\n",
    "        torch.distributed.gather(topk_sims, topk_sims_rank, dst=target_rank)\n",
    "        torch.distributed.gather(\n",
    "            neighbors_labels,\n",
    "            retrieved_rank,\n",
    "            dst=target_rank,\n",
    "        )\n",
    "\n",
    "        if self.global_rank == target_rank:\n",
    "            # Perform a second top-k on the k * global_size retrieved neighbors\n",
    "            topk_sims_rank = torch.cat(topk_sims_rank, dim=1)\n",
    "            retrieved_rank = torch.cat(retrieved_rank, dim=1)\n",
    "            results = self._get_knn_sims_and_labels(topk_sims_rank, retrieved_rank)\n",
    "            return results\n",
    "        return None\n",
    "\n",
    "    def compute_neighbors(self, features_rank):\n",
    "        for rank in range(self.global_size):\n",
    "            topk_sims, neighbors_labels = self._similarity_for_rank(features_rank, rank)\n",
    "            results = self._gather_all_knn_for_rank(topk_sims, neighbors_labels, rank)\n",
    "            if results is not None:\n",
    "                topk_sims_rank, neighbors_labels_rank = results\n",
    "        return topk_sims_rank, neighbors_labels_rank\n",
    "\n",
    "    def forward(self, features_rank):\n",
    "        \"\"\"\n",
    "        Compute the results on all values of `self.nb_knn` neighbors from the full `self.max_k`\n",
    "        \"\"\"\n",
    "        assert all(k <= self.max_k for k in self.nb_knn)\n",
    "\n",
    "        topk_sims, neighbors_labels = self.compute_neighbors(features_rank)\n",
    "        batch_size = neighbors_labels.shape[0]\n",
    "        topk_sims_transform = softmax(topk_sims / self.T, 1)\n",
    "        matmul = torch.mul(\n",
    "            one_hot(\n",
    "                neighbors_labels,\n",
    "                num_classes=self.num_classes,\n",
    "            ),\n",
    "            topk_sims_transform.view(batch_size, -1, 1),\n",
    "        )\n",
    "        probas_for_k = {k: torch.sum(matmul[:, :k, :], 1) for k in self.nb_knn}\n",
    "        return probas_for_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDictKeysModule\u001b[39;00m(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class DictKeysModule(torch.nn.Module):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "\n",
    "    def forward(self, features_dict, targets):\n",
    "        for k in self.keys:\n",
    "            features_dict = features_dict[k]\n",
    "        return {\"preds\": features_dict, \"target\": targets}\n",
    "\n",
    "\n",
    "def create_module_dict(\n",
    "    *,\n",
    "    module,\n",
    "    n_per_class_list,\n",
    "    n_tries,\n",
    "    nb_knn,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "):\n",
    "    modules = {}\n",
    "    mapping = create_class_indices_mapping(train_labels)\n",
    "    for npc in n_per_class_list:\n",
    "        if npc < 0:  # Only one try needed when using the full data\n",
    "            full_module = module(\n",
    "                train_features=train_features,\n",
    "                train_labels=train_labels,\n",
    "                nb_knn=nb_knn,\n",
    "            )\n",
    "            modules[\"full\"] = ModuleDictWithForward({\"1\": full_module})\n",
    "            continue\n",
    "        all_tries = {}\n",
    "        for t in range(n_tries):\n",
    "            final_indices = filter_train(mapping, npc, seed=t)\n",
    "            k_list = list(set(nb_knn + [npc]))\n",
    "            k_list = sorted([el for el in k_list if el <= npc])\n",
    "            all_tries[str(t)] = module(\n",
    "                train_features=train_features[final_indices],\n",
    "                train_labels=train_labels[final_indices],\n",
    "                nb_knn=k_list,\n",
    "            )\n",
    "        modules[f\"{npc} per class\"] = ModuleDictWithForward(all_tries)\n",
    "\n",
    "    return ModuleDictWithForward(modules)\n",
    "\n",
    "\n",
    "def filter_train(mapping, n_per_class, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    final_indices = []\n",
    "    for k in mapping.keys():\n",
    "        index = torch.randperm(len(mapping[k]))[:n_per_class]\n",
    "        final_indices.append(mapping[k][index])\n",
    "    return torch.cat(final_indices).squeeze()\n",
    "\n",
    "\n",
    "def create_class_indices_mapping(labels):\n",
    "    unique_labels, inverse = torch.unique(labels, return_inverse=True)\n",
    "    mapping = {unique_labels[i]: (inverse == i).nonzero() for i in range(len(unique_labels))}\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleDictWithForward(torch.nn.ModuleDict):\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return {k: module(*args, **kwargs) for k, module in self._modules.items()}\n",
    "\n",
    "\n",
    "def eval_knn(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    accuracy_averaging,\n",
    "    nb_knn,\n",
    "    temperature,\n",
    "    batch_size,\n",
    "    num_workers,\n",
    "    gather_on_cpu,\n",
    "    n_per_class_list=[-1],\n",
    "    n_tries=1,\n",
    "):\n",
    "    model = ModelWithNormalize(model)\n",
    "\n",
    "    logger.info(\"Extracting features for train set...\")\n",
    "    train_features, train_labels = extract_features(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        batch_size,\n",
    "        num_workers,\n",
    "        gather_on_cpu=gather_on_cpu,\n",
    "    )\n",
    "    logger.info(f\"Train features created, shape {train_features.shape}.\")\n",
    "\n",
    "    val_dataloader = make_data_loader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        sampler_type=SamplerType.DISTRIBUTED,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "    num_classes = int(train_labels.max() + 1)\n",
    "    print(\"Train num_classes\", num_classes)\n",
    "    metric_collection = build_topk_accuracy_metric(accuracy_averaging, num_classes=num_classes)\n",
    "\n",
    "    device = torch.cuda.current_device()\n",
    "    partial_module = partial(\n",
    "        KnnModule,\n",
    "        T=temperature,\n",
    "        device=device,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "    knn_module_dict = create_module_dict(\n",
    "        module=partial_module,\n",
    "        n_per_class_list=n_per_class_list,\n",
    "        n_tries=n_tries,\n",
    "        nb_knn=nb_knn,\n",
    "        train_features=train_features,\n",
    "        train_labels=train_labels,\n",
    "    )\n",
    "    postprocessors, metrics = {}, {}\n",
    "    for n_per_class, knn_module in knn_module_dict.items():\n",
    "        for t, knn_try in knn_module.items():\n",
    "            postprocessors = {\n",
    "                **postprocessors,\n",
    "                **{(n_per_class, t, k): DictKeysModule([n_per_class, t, k]) for k in knn_try.nb_knn},\n",
    "            }\n",
    "            metrics = {\n",
    "                **metrics,\n",
    "                **{\n",
    "                    (\n",
    "                        n_per_class,\n",
    "                        t,\n",
    "                        k,\n",
    "                    ): metric_collection.clone()\n",
    "                    for k in knn_try.nb_knn\n",
    "                },\n",
    "            }\n",
    "    model_with_knn = torch.nn.Sequential(model, knn_module_dict)\n",
    "\n",
    "    # ============ evaluation ... ============\n",
    "    logger.info(\"Start the k-NN classification.\")\n",
    "    _, results_dict = evaluate(\n",
    "        model_with_knn,\n",
    "        val_dataloader,\n",
    "        postprocessors,\n",
    "        metrics,\n",
    "        device,\n",
    "    )\n",
    "\n",
    "    # Averaging the results over the n tries for each value of n_per_class\n",
    "    for n_per_class, knn_module in knn_module_dict.items():\n",
    "        first_try = list(knn_module.keys())[0]\n",
    "        k_list = knn_module[first_try].nb_knn\n",
    "        for k in k_list:\n",
    "            keys = results_dict[(n_per_class, first_try, k)].keys()  # keys are e.g. `top-1` and `top-5`\n",
    "            results_dict[(n_per_class, k)] = {\n",
    "                key: torch.mean(torch.stack([results_dict[(n_per_class, t, k)][key] for t in knn_module.keys()]))\n",
    "                for key in keys\n",
    "                if \"confmat\" not in key\n",
    "            }\n",
    "            if \"confmat\" in keys:\n",
    "                results_dict[(n_per_class, k)][\"confmat\"] = torch.sum(\n",
    "                    torch.stack([results_dict[(n_per_class, t, k)][\"confmat\"] for t in knn_module.keys()]),\n",
    "                    dim=0,\n",
    "                )\n",
    "\n",
    "            for t in knn_module.keys():\n",
    "                del results_dict[(n_per_class, t, k)]\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_knn_with_model(\n",
    "    model,\n",
    "    output_dir,\n",
    "    train_dataset_str=\"ImageNet:split=TRAIN\",\n",
    "    val_dataset_str=\"ImageNet:split=VAL\",\n",
    "    nb_knn=(10, 20, 100, 200),\n",
    "    temperature=0.07,\n",
    "    autocast_dtype=torch.float,\n",
    "    accuracy_averaging=AccuracyAveraging.MEAN_ACCURACY,\n",
    "    transform=None,\n",
    "    gather_on_cpu=False,\n",
    "    batch_size=256,\n",
    "    num_workers=5,\n",
    "    n_per_class_list=[-1],\n",
    "    n_tries=1,\n",
    "):\n",
    "    transform = transform or make_classification_eval_transform()\n",
    "\n",
    "    train_dataset = make_dataset(\n",
    "        dataset_str=train_dataset_str,\n",
    "        transform=transform,\n",
    "    )\n",
    "    val_dataset = make_dataset(\n",
    "        dataset_str=val_dataset_str,\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "    with torch.cuda.amp.autocast(dtype=autocast_dtype):\n",
    "        results_dict_knn = eval_knn(\n",
    "            model=model,\n",
    "            train_dataset=train_dataset,\n",
    "            val_dataset=val_dataset,\n",
    "            accuracy_averaging=accuracy_averaging,\n",
    "            nb_knn=nb_knn,\n",
    "            temperature=temperature,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            gather_on_cpu=gather_on_cpu,\n",
    "            n_per_class_list=n_per_class_list,\n",
    "            n_tries=n_tries,\n",
    "        )\n",
    "\n",
    "    results_dict, confmats_dict = {}, {}\n",
    "    if distributed.is_main_process():\n",
    "        for knn_ in results_dict_knn.keys():\n",
    "            metric_log_msg = f\"KNN {knn_[1]} classifier result: \"\n",
    "            for metric_name in results_dict_knn[knn_].keys():\n",
    "                metric_val = results_dict_knn[knn_][metric_name]\n",
    "                if \"confmat\" in metric_name:\n",
    "                    metric_val = metric_val.cpu()\n",
    "                    confmats_dict[knn_] = np.array(metric_val, dtype=np.uint)\n",
    "                else:\n",
    "                    metric_val = metric_val.item()\n",
    "                    results_dict[f\"{knn_} {metric_name}\"] = metric_val\n",
    "                    metric_log_msg += f\"{metric_name}: {metric_val:.4f} \"\n",
    "                if \"confmat\" not in metric_name:\n",
    "                    logger.info(metric_log_msg)\n",
    "\n",
    "    # save in ckpt dir\n",
    "    metrics_file_path = os.path.join(output_dir, \"results_eval_knn.json\")\n",
    "    with open(metrics_file_path, \"a\") as f:\n",
    "        for k, v in results_dict.items():\n",
    "            f.write(json.dumps({k: v}) + \"\\n\")\n",
    "\n",
    "    confmat_file_path = os.path.join(output_dir, \"confmats_knn\")\n",
    "    os.makedirs(confmat_file_path, exist_ok=True)\n",
    "    np.save(confmat_file_path + \".npy\", confmats_dict)\n",
    "    for k, v in confmats_dict.items():\n",
    "        knn_nb = re.search(\"[0-9]+\", str(k))\n",
    "        if knn_nb:\n",
    "            knn_nb = knn_nb.group(0)\n",
    "        else:\n",
    "            knn_nb = k\n",
    "        np.save(\n",
    "            os.path.join(confmat_file_path, f\"knn_{knn_nb}\"),\n",
    "            v,\n",
    "        )\n",
    "\n",
    "    if distributed.is_enabled():\n",
    "        torch.distributed.barrier()\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    model, autocast_dtype = setup_and_build_model(args, do_eval=True)\n",
    "\n",
    "    print(\"args.output_dir\", args.output_dir)\n",
    "    eval_knn_with_model(\n",
    "        model=model,\n",
    "        output_dir=args.output_dir_ckpt,\n",
    "        train_dataset_str=args.train_dataset_str,\n",
    "        val_dataset_str=args.val_dataset_str,\n",
    "        nb_knn=args.nb_knn,\n",
    "        temperature=args.temperature,\n",
    "        autocast_dtype=autocast_dtype,\n",
    "        accuracy_averaging=AccuracyAveraging.MEAN_ACCURACY,\n",
    "        transform=None,\n",
    "        gather_on_cpu=args.gather_on_cpu,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        n_per_class_list=args.n_per_class_list,\n",
    "        n_tries=args.n_tries,\n",
    "    )\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    description = \"DINOv2 k-NN evaluation\"\n",
    "    args_parser = get_args_parser(description=description)\n",
    "    args = args_parser.parse_args()\n",
    "    sys.exit(main(args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
