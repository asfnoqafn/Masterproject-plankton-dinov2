{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hkfs/home/project/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2\n",
      "/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/bin/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/'\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "sys.path.append('/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hkn0401.localdomain\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py\", line 19, in <module>\n",
      "    import dinov2.distributed as distributed\n",
      "ModuleNotFoundError: No module named 'dinov2'\n"
     ]
    }
   ],
   "source": [
    "!python /home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py --train-dataset=\"LMDBDataset:split=TRAIN:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2\" \\\n",
    "--val_dataset=\"LMDBDataset:split=VAL:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2\" \\\n",
    "--config-file Masterproject-plankton-dinov2/dinov2/configs/eval/vits14_pretrain.yaml \\\n",
    "--pretrained-weights 'checkpoints/dinov2_vits14_pretrain.pth' --output-dir \\\n",
    "/home/hk-project-p0021769/hgf_grc7525/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/layers/attention.py:32: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/layers/block.py:40: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dataset: \"LMDBDataset:split=TRAIN:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2:extra=*\"\n",
      "key:\n",
      "split\n",
      "value:\n",
      "TRAIN\n",
      "key:\n",
      "root\n",
      "value:\n",
      "/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2\n",
      "key:\n",
      "extra\n",
      "value:\n",
      "*\n",
      "Dataset kwargs {'split': <_Split.TRAIN: 'train'>, 'root': '/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2', 'extra': '*'}\n",
      "extra_path /home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/*-TRAIN_*\n",
      "extra full path /home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/*\n",
      "Datasets labels file list:  ['/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-TRAIN_labels']\n",
      "Datasets imgs file list:  ['/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-TRAIN_imgs']\n",
      "\n",
      "/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-TRAIN_imgs lmdb_env_imgs.stat() {'psize': 4096, 'depth': 4, 'branch_pages': 123, 'leaf_pages': 9226, 'overflow_pages': 73201, 'entries': 55221}\n",
      "using dataset: \"LMDBDataset:split=VAL:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/:extra=*\"\n",
      "key:\n",
      "split\n",
      "value:\n",
      "VAL\n",
      "key:\n",
      "root\n",
      "value:\n",
      "/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/\n",
      "key:\n",
      "extra\n",
      "value:\n",
      "*\n",
      "Dataset kwargs {'split': <_Split.VAL: 'val'>, 'root': '/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/', 'extra': '*'}\n",
      "extra_path /home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/*-VAL_*\n",
      "extra full path /home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/*\n",
      "Datasets labels file list:  ['/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-VAL_labels']\n",
      "Datasets imgs file list:  ['/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-VAL_imgs']\n",
      "\n",
      "/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-VAL_imgs lmdb_env_imgs.stat() {'psize': 4096, 'depth': 3, 'branch_pages': 30, 'leaf_pages': 2313, 'overflow_pages': 18274, 'entries': 13806}\n",
      "args.run_name  knn_run_17112024_171609_vit_small\n",
      "Torch dist initialized\n",
      "num_nodes 1\n",
      "Parsed nodes ['hkn0402']\n",
      "get_local_rank 0\n",
      "get_global_rank 0\n",
      "get_global_size 1\n",
      "get_local_size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: nicklechtenborger. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.18.5\n",
      "wandb: Run data is saved locally in output/vits14_pretrain/knn_run_17112024_171609_vit_small/wandb/run-20241117_171610-9fd3xunk\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run knn_run_17112024_171609_vit_small\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/nicklechtenborger/mp_aqqua\n",
      "wandb: üöÄ View run at https://wandb.ai/nicklechtenborger/mp_aqqua/runs/9fd3xunk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git:\n",
      "  sha: 27c65b13d5ac6bbe402971ebd3034fb5c4c66664, status: has uncommitted changes, branch: nick_dev\n",
      "\n",
      "batch_size: 256\n",
      "config_file: /home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/configs/eval/vits14_pretrain.yaml\n",
      "gather_on_cpu: False\n",
      "n_per_class_list: [-1]\n",
      "n_tries: 1\n",
      "nb_knn: [10, 20, 100, 200]\n",
      "num_nodes: 1\n",
      "num_workers: 4\n",
      "opts: [' --standalone', '--nnodes=1']\n",
      "output_dir: /home/hk-project-p0021769/hgf_grc7525/output/\n",
      "pretrained_weights: /home/hk-project-p0021769/hgf_grc7525/checkpoints/dinov2_vits14_pretrain.pth\n",
      "run_name: knn_run_17112024_171609_vit_small\n",
      "temperature: 0.07\n",
      "train_dataset_str: LMDBDataset:split=TRAIN:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2:extra=*\n",
      "val_dataset_str: LMDBDataset:split=VAL:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/:extra=*\n",
      "sqrt scaling learning rate; base: 0.0005, new: 0.00025\n",
      "MODEL:\n",
      "  WEIGHTS: ''\n",
      "compute_precision:\n",
      "  grad_scaler: true\n",
      "  teacher:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "  student:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "dino:\n",
      "  loss_weight: 1.0\n",
      "  head_n_prototypes: 65536\n",
      "  head_bottleneck_dim: 256\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "  koleo_loss_weight: 0.1\n",
      "ibot:\n",
      "  loss_weight: 1.0\n",
      "  mask_sample_probability: 0.5\n",
      "  mask_ratio_min_max:\n",
      "  - 0.1\n",
      "  - 0.5\n",
      "  separate_head: false\n",
      "  head_n_prototypes: 65536\n",
      "  head_bottleneck_dim: 256\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "train:\n",
      "  batch_size_per_gpu: 256\n",
      "  dataset_path: LMDBDataset:split=ALL:root=/fast/AG_Kainmueller/plankton/data/WHOI/preprocessed/preprocessed_lmdb/:extra=*\n",
      "  output_dir: output/vits14_pretrain/knn_run_17112024_171609_vit_small\n",
      "  saveckp_freq: 10\n",
      "  seed: 0\n",
      "  num_workers: 8\n",
      "  OFFICIAL_EPOCH_LENGTH: 1250\n",
      "  cache_dataset: false\n",
      "  centering: sinkhorn_knopp\n",
      "  use_torch_compile: true\n",
      "  do_profiling: false\n",
      "  augmentations: false\n",
      "  in_chans: 1\n",
      "  do_debug: false\n",
      "student:\n",
      "  arch: vit_small\n",
      "  patch_size: 14\n",
      "  drop_path_rate: 0\n",
      "  layerscale: 1.0e-05\n",
      "  drop_path_uniform: true\n",
      "  pretrained_weights: checkpoints/dinov2_vits14_pretrain.pth\n",
      "  ffn_layer: mlp\n",
      "  block_chunks: 0\n",
      "  qkv_bias: true\n",
      "  proj_bias: true\n",
      "  ffn_bias: true\n",
      "  num_register_tokens: 0\n",
      "  interpolate_antialias: false\n",
      "  interpolate_offset: 0.1\n",
      "teacher:\n",
      "  momentum_teacher: 0.992\n",
      "  final_momentum_teacher: 1\n",
      "  warmup_teacher_temp: 0.04\n",
      "  teacher_temp: 0.07\n",
      "  warmup_teacher_temp_epochs: 30\n",
      "optim:\n",
      "  epochs: 100\n",
      "  weight_decay: 0.04\n",
      "  weight_decay_end: 0.4\n",
      "  base_lr: 0.0005\n",
      "  lr: 0.00025\n",
      "  warmup_epochs: 10\n",
      "  min_lr: 1.0e-06\n",
      "  clip_grad: 3.0\n",
      "  freeze_last_layer_epochs: 1\n",
      "  scaling_rule: sqrt_wrt_1024\n",
      "  patch_embed_lr_mult: 0.2\n",
      "  layerwise_decay: 0.9\n",
      "  adamw_beta1: 0.9\n",
      "  adamw_beta2: 0.999\n",
      "crops:\n",
      "  global_crops_scale:\n",
      "  - 0.32\n",
      "  - 1.0\n",
      "  local_crops_number: 8\n",
      "  local_crops_scale:\n",
      "  - 0.05\n",
      "  - 0.32\n",
      "  global_crops_size: 224\n",
      "  local_crops_size: 98\n",
      "  use_native_res: false\n",
      "  free_shapes: false\n",
      "  use_ch_patch_embed: true\n",
      "  use_variable_channels: true\n",
      "evaluation:\n",
      "  eval_period_iterations: 12500\n",
      "' --standalone': null\n",
      "--nnodes: 1\n",
      "\n",
      "---- Using PatchEmbedPerChannel, with 1 channels ----\n",
      "using MLP layer as FFN\n",
      "Positional embeddings have different shapes, matching them... pos_embed_ref: torch.Size([1, 257, 384]), pos_embed_loaded: torch.Size([1, 1370, 384])\n",
      "Pretrained weights found at /home/hk-project-p0021769/hgf_grc7525/checkpoints/dinov2_vits14_pretrain.pth and loaded with msg: _IncompatibleKeys(missing_keys=['patch_embed.channel_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias'], unexpected_keys=[])\n",
      "args.output_dir /home/hk-project-p0021769/hgf_grc7525/output/\n",
      "/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "\n",
      "using dataset: \"LMDBDataset:split=TRAIN:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2:extra=*\"\n",
      "using dataset: \"LMDBDataset:split=TRAIN:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2:extra=*\"\n",
      "key:\n",
      "split\n",
      "value:\n",
      "TRAIN\n",
      "key:\n",
      "root\n",
      "value:\n",
      "/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2\n",
      "key:\n",
      "extra\n",
      "value:\n",
      "*\n",
      "Dataset kwargs {'split': <_Split.TRAIN: 'train'>, 'root': '/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2', 'extra': '*'}\n",
      "extra_path /home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/*-TRAIN_*\n",
      "extra full path /home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/*\n",
      "Datasets labels file list:  ['/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-TRAIN_labels']\n",
      "Datasets imgs file list:  ['/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-TRAIN_imgs']\n",
      "\n",
      "/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-TRAIN_imgs lmdb_env_imgs.stat() {'psize': 4096, 'depth': 4, 'branch_pages': 123, 'leaf_pages': 9226, 'overflow_pages': 73201, 'entries': 55221}\n",
      "# of dataset samples: 55,221\n",
      "train_dataset: 55221\n",
      "using dataset: \"LMDBDataset:split=VAL:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/:extra=*\"\n",
      "using dataset: \"LMDBDataset:split=VAL:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/:extra=*\"\n",
      "key:\n",
      "split\n",
      "value:\n",
      "VAL\n",
      "key:\n",
      "root\n",
      "value:\n",
      "/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/\n",
      "key:\n",
      "extra\n",
      "value:\n",
      "*\n",
      "Dataset kwargs {'split': <_Split.VAL: 'val'>, 'root': '/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/', 'extra': '*'}\n",
      "extra_path /home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/*-VAL_*\n",
      "extra full path /home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/*\n",
      "Datasets labels file list:  ['/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-VAL_labels']\n",
      "Datasets imgs file list:  ['/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-VAL_imgs']\n",
      "\n",
      "/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/a-VAL_imgs lmdb_env_imgs.stat() {'psize': 4096, 'depth': 3, 'branch_pages': 30, 'leaf_pages': 2313, 'overflow_pages': 18274, 'entries': 13806}\n",
      "# of dataset samples: 13,806\n",
      "val_dataset: 13806\n",
      "Extracting features for train set...\n",
      "sample_count: 55221\n",
      "sampler: distributed\n",
      "using PyTorch data loader\n",
      "# of batches: 216\n",
      "extract_features_with_dataloader\n",
      "prepare_tokens_with_masks x.shape local_patch_pos local_crop_dims local_crop_len num_ch_list\n",
      "prepare_tokens_with_masks torch.Size([256, 1, 224, 224]) None None None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py\", line 545, in <module>\n",
      "    sys.exit(main(args))\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py\", line 504, in main\n",
      "    eval_knn_with_model(\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py\", line 444, in eval_knn_with_model\n",
      "    results_dict_knn = eval_knn(\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py\", line 324, in eval_knn\n",
      "    train_features, train_labels = extract_features(\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/utils.py\", line 125, in extract_features\n",
      "    return extract_features_with_dataloader(model, data_loader, sample_count, gather_on_cpu)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/utils.py\", line 144, in extract_features_with_dataloader\n",
      "    features_rank = model(samples).float()\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/utils.py\", line 30, in forward\n",
      "    return nn.functional.normalize(self.model(samples), dim=1, p=2)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/models/vision_transformer.py\", line 752, in forward\n",
      "    ret = self.forward_features(*args, **kwargs)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/models/vision_transformer.py\", line 654, in forward_features\n",
      "    x = self.prepare_tokens_with_masks(x, masks, num_ch_list=num_ch_list)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/models/vision_transformer.py\", line 513, in prepare_tokens_with_masks\n",
      "    interpolated_pos_embeds = torch.cat(pos_embeds, dim=0)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.10 GiB. GPU 0 has a total capacity of 39.38 GiB of which 13.81 GiB is free. Including non-PyTorch memory, this process has 25.54 GiB memory in use. Of the allocated memory 24.32 GiB is allocated by PyTorch, and 425.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py\", line 545, in <module>\n",
      "    sys.exit(main(args))\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py\", line 504, in main\n",
      "    eval_knn_with_model(\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py\", line 444, in eval_knn_with_model\n",
      "    results_dict_knn = eval_knn(\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py\", line 324, in eval_knn\n",
      "    train_features, train_labels = extract_features(\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/utils.py\", line 125, in extract_features\n",
      "    return extract_features_with_dataloader(model, data_loader, sample_count, gather_on_cpu)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/utils.py\", line 144, in extract_features_with_dataloader\n",
      "    features_rank = model(samples).float()\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/utils.py\", line 30, in forward\n",
      "    return nn.functional.normalize(self.model(samples), dim=1, p=2)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/models/vision_transformer.py\", line 752, in forward\n",
      "    ret = self.forward_features(*args, **kwargs)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/models/vision_transformer.py\", line 654, in forward_features\n",
      "    x = self.prepare_tokens_with_masks(x, masks, num_ch_list=num_ch_list)\n",
      "  File \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/models/vision_transformer.py\", line 513, in prepare_tokens_with_masks\n",
      "    interpolated_pos_embeds = torch.cat(pos_embeds, dim=0)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.10 GiB. GPU 0 has a total capacity of 39.38 GiB of which 13.81 GiB is free. Including non-PyTorch memory, this process has 25.54 GiB memory in use. Of the allocated memory 24.32 GiB is allocated by PyTorch, and 425.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mknn_run_17112024_171609_vit_small\u001b[0m at: \u001b[34mhttps://wandb.ai/nicklechtenborger/mp_aqqua/runs/9fd3xunk\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-17 17:16:40,679] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 3833695) of binary: /hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/bin/torchrun\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('torch==2.2.2', 'console_scripts', 'torchrun')())\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/distributed/run.py\", line 812, in main\n",
      "    run(args)\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/distributed/run.py\", line 803, in run\n",
      "    elastic_launch(\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 135, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 268, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-11-17_17:16:40\n",
      "  host      : hkn0402.localdomain\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 3833695)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'PYTHONPATH=/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2 torchrun \\\\\\n/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py --train-dataset=\"LMDBDataset:split=TRAIN:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2:extra=*\" \\\\\\n--val-dataset=\"LMDBDataset:split=VAL:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/:extra=*\" \\\\\\n--config-file \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/configs/eval/vits14_pretrain.yaml\" \\\\\\n--pretrained-weights \\'/home/hk-project-p0021769/hgf_grc7525/checkpoints/dinov2_vits14_pretrain.pth\\' --output-dir \\\\\\n/home/hk-project-p0021769/hgf_grc7525/output/ \\\\ --standalone --nnodes=1\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPYTHONPATH=/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2 torchrun \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py --train-dataset=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLMDBDataset:split=TRAIN:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2:extra=*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m--val-dataset=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLMDBDataset:split=VAL:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/:extra=*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m--config-file \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/configs/eval/vits14_pretrain.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m--pretrained-weights \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m/home/hk-project-p0021769/hgf_grc7525/checkpoints/dinov2_vits14_pretrain.pth\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m --output-dir \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m/home/hk-project-p0021769/hgf_grc7525/output/ \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m --standalone --nnodes=1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/IPython/core/magics/script.py:155\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hkfs/home/project/hk-project-p0021769/hgf_grc7525/micromamba/envs/dinov2_2/lib/python3.10/site-packages/IPython/core/magics/script.py:315\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'PYTHONPATH=/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2 torchrun \\\\\\n/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py --train-dataset=\"LMDBDataset:split=TRAIN:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2:extra=*\" \\\\\\n--val-dataset=\"LMDBDataset:split=VAL:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/:extra=*\" \\\\\\n--config-file \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/configs/eval/vits14_pretrain.yaml\" \\\\\\n--pretrained-weights \\'/home/hk-project-p0021769/hgf_grc7525/checkpoints/dinov2_vits14_pretrain.pth\\' --output-dir \\\\\\n/home/hk-project-p0021769/hgf_grc7525/output/ \\\\ --standalone --nnodes=1\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "PYTHONPATH=/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2 torchrun \\\n",
    "/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/eval/knn.py --train-dataset=\"LMDBDataset:split=TRAIN:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2:extra=*\" \\\n",
    "--val-dataset=\"LMDBDataset:split=VAL:root=/home/hk-project-p0021769/hgf_grc7525/workspace/hkfswork/hgf_grc7525-nick/out2/:extra=*\" \\\n",
    "--config-file \"/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/configs/eval/vits14_pretrain.yaml\" \\\n",
    "--pretrained-weights '/home/hk-project-p0021769/hgf_grc7525/checkpoints/dinov2_vits14_pretrain.pth' --output-dir \\\n",
    "/home/hk-project-p0021769/hgf_grc7525/output/ \\ --standalone --nnodes=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
