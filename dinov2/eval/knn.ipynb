{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/nick/Documents/ws24/Masterproject-plankton-dinov2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dinov2 in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (0.0.1.dev0)\n",
      "Requirement already satisfied: torch in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (from dinov2) (2.2.2)\n",
      "Requirement already satisfied: filelock in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (from torch->dinov2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (from torch->dinov2) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (from torch->dinov2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (from torch->dinov2) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (from torch->dinov2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (from torch->dinov2) (2024.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (from jinja2->torch->dinov2) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nick/anaconda3/envs/dinov2_2/lib/python3.10/site-packages (from sympy->torch->dinov2) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from functools import partial\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import one_hot, softmax\n",
    "\n",
    "# Install the dinov2 package\n",
    "%pip install dinov2\n",
    "\n",
    "import dinov2.distributed as distributed\n",
    "from dinov2.data import (\n",
    "    SamplerType,\n",
    "    make_data_loader,\n",
    "    make_dataset,\n",
    ")\n",
    "from dinov2.data.transforms import (\n",
    "    make_classification_eval_transform,\n",
    ")\n",
    "from dinov2.eval.metrics import (\n",
    "    AccuracyAveraging,\n",
    "    build_topk_accuracy_metric,\n",
    ")\n",
    "from dinov2.eval.setup import (\n",
    "    get_args_parser as get_setup_args_parser,\n",
    ")\n",
    "from dinov2.eval.setup import setup_and_build_model\n",
    "from dinov2.eval.utils import (\n",
    "    ModelWithNormalize,\n",
    "    evaluate,\n",
    "    extract_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/envs/dinov2_2/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "sys.path.append('/home/hk-project-p0021769/hgf_grc7525/Masterproject-plankton-dinov2/dinov2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nick/anaconda3/envs/dinov2_2/bin/python'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"dinov2\")\n",
    "\n",
    "\n",
    "def get_args_parser(\n",
    "    description: Optional[str] = None,\n",
    "    parents: Optional[List[argparse.ArgumentParser]] = None,\n",
    "    add_help: bool = True,\n",
    "):\n",
    "    parents = parents or []\n",
    "    setup_args_parser = get_setup_args_parser(parents=parents, add_help=False)\n",
    "    parents = [setup_args_parser]\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=description,\n",
    "        parents=parents,\n",
    "        add_help=add_help,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dataset_str\",\n",
    "        dest=\"dataset_str\",\n",
    "        type=str,\n",
    "        help=\"Training dataset\",\n",
    "    )\n",
    "#    parser.add_argument(\n",
    "#        \"--val-dataset\",\n",
    "#        dest=\"val_dataset_str\",\n",
    "#        type=str,\n",
    "#        help=\"Validation dataset\",\n",
    "#    )\n",
    "    parser.add_argument(\n",
    "        \"--nb_knn\",\n",
    "        nargs=\"+\",\n",
    "        type=int,\n",
    "        help=\"Number of NN to use. 20 is usually working the best.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--temperature\",\n",
    "        type=float,\n",
    "        help=\"Temperature used in the voting coefficient\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gather-on-cpu\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Whether to gather the train features on cpu, slower\"\n",
    "        \"but useful to avoid OOM for large datasets (e.g. ImageNet22k).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch-size\",\n",
    "        type=int,\n",
    "        help=\"Batch size.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-workers\",\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help=\"Number of workers in DataLoader.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--n-per-class-list\",\n",
    "        nargs=\"+\",\n",
    "        type=int,\n",
    "        help=\"Number to take per class\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--n-tries\",\n",
    "        type=int,\n",
    "        help=\"Number of tries\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--run_name\",\n",
    "        type=str,\n",
    "        help=\"Name for the wandb log\",\n",
    "        default=\"knn_run\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_nodes\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Set number of nodes used.\",\n",
    "    )\n",
    "    parser.set_defaults(\n",
    "        dataset_str=\"ImageNet:split=TRAIN\",\n",
    "        #val_dataset_str=\"ImageNet:split=VAL\",\n",
    "        nb_knn=[10, 20, 100, 200],\n",
    "        temperature=0.07,\n",
    "        batch_size=256,\n",
    "        n_per_class_list=[-1],\n",
    "        n_tries=1,\n",
    "    )\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Gets knn of test features from all processes on a chunk of the train features\n",
    "\n",
    "    Each rank gets a chunk of the train features as well as a chunk of the test features.\n",
    "    In `compute_neighbors`, for each rank one after the other, its chunk of test features\n",
    "    is sent to all devices, partial knns are computed with each chunk of train features\n",
    "    then collated back on the original device.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        nb_knn,\n",
    "        T,\n",
    "        device,\n",
    "        num_classes=1000,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.global_rank = distributed.get_global_rank()\n",
    "        self.global_size = distributed.get_global_size()\n",
    "\n",
    "        self.device = device\n",
    "        self.train_features_rank_T = train_features.chunk(self.global_size)[self.global_rank].T.to(self.device)\n",
    "        self.candidates = train_labels.chunk(self.global_size)[self.global_rank].view(1, -1).to(self.device)\n",
    "\n",
    "        self.nb_knn = nb_knn\n",
    "        self.max_k = max(self.nb_knn)\n",
    "        self.T = T\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def _get_knn_sims_and_labels(self, similarity, train_labels):\n",
    "        topk_sims, indices = similarity.topk(self.max_k, largest=True, sorted=True)\n",
    "        neighbors_labels = torch.gather(train_labels, 1, indices)\n",
    "        return topk_sims, neighbors_labels\n",
    "\n",
    "    def _similarity_for_rank(self, features_rank, source_rank):\n",
    "        # Send the features from `source_rank` to all ranks\n",
    "        broadcast_shape = torch.tensor(features_rank.shape).to(self.device)\n",
    "        torch.distributed.broadcast(broadcast_shape, source_rank)\n",
    "\n",
    "        broadcasted = features_rank\n",
    "        if self.global_rank != source_rank:\n",
    "            broadcasted = torch.zeros(\n",
    "                *broadcast_shape,\n",
    "                dtype=features_rank.dtype,\n",
    "                device=self.device,\n",
    "            )\n",
    "        torch.distributed.broadcast(broadcasted, source_rank)\n",
    "\n",
    "        # Compute the neighbors for `source_rank` among `train_features_rank_T`\n",
    "        similarity_rank = torch.mm(broadcasted, self.train_features_rank_T)\n",
    "        candidate_labels = self.candidates.expand(len(similarity_rank), -1)\n",
    "        return self._get_knn_sims_and_labels(similarity_rank, candidate_labels)\n",
    "\n",
    "    def _gather_all_knn_for_rank(self, topk_sims, neighbors_labels, target_rank):\n",
    "        # Gather all neighbors for `target_rank`\n",
    "        topk_sims_rank = retrieved_rank = None\n",
    "        if self.global_rank == target_rank:\n",
    "            topk_sims_rank = [torch.zeros_like(topk_sims) for _ in range(self.global_size)]\n",
    "            retrieved_rank = [torch.zeros_like(neighbors_labels) for _ in range(self.global_size)]\n",
    "\n",
    "        torch.distributed.gather(topk_sims, topk_sims_rank, dst=target_rank)\n",
    "        torch.distributed.gather(\n",
    "            neighbors_labels,\n",
    "            retrieved_rank,\n",
    "            dst=target_rank,\n",
    "        )\n",
    "\n",
    "        if self.global_rank == target_rank:\n",
    "            # Perform a second top-k on the k * global_size retrieved neighbors\n",
    "            topk_sims_rank = torch.cat(topk_sims_rank, dim=1)\n",
    "            retrieved_rank = torch.cat(retrieved_rank, dim=1)\n",
    "            results = self._get_knn_sims_and_labels(topk_sims_rank, retrieved_rank)\n",
    "            return results\n",
    "        return None\n",
    "\n",
    "    def compute_neighbors(self, features_rank):\n",
    "        for rank in range(self.global_size):\n",
    "            topk_sims, neighbors_labels = self._similarity_for_rank(features_rank, rank)\n",
    "            results = self._gather_all_knn_for_rank(topk_sims, neighbors_labels, rank)\n",
    "            if results is not None:\n",
    "                topk_sims_rank, neighbors_labels_rank = results\n",
    "        return topk_sims_rank, neighbors_labels_rank\n",
    "\n",
    "    def forward(self, features_rank):\n",
    "        \"\"\"\n",
    "        Compute the results on all values of `self.nb_knn` neighbors from the full `self.max_k`\n",
    "        \"\"\"\n",
    "        assert all(k <= self.max_k for k in self.nb_knn)\n",
    "\n",
    "        topk_sims, neighbors_labels = self.compute_neighbors(features_rank)\n",
    "        batch_size = neighbors_labels.shape[0]\n",
    "        topk_sims_transform = softmax(topk_sims / self.T, 1)\n",
    "        matmul = torch.mul(\n",
    "            one_hot(\n",
    "                neighbors_labels,\n",
    "                num_classes=self.num_classes,\n",
    "            ),\n",
    "            topk_sims_transform.view(batch_size, -1, 1),\n",
    "        )\n",
    "        probas_for_k = {k: torch.sum(matmul[:, :k, :], 1) for k in self.nb_knn}\n",
    "        return probas_for_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictKeysModule(torch.nn.Module):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "\n",
    "    def forward(self, features_dict, targets):\n",
    "        for k in self.keys:\n",
    "            features_dict = features_dict[k]\n",
    "        return {\"preds\": features_dict, \"target\": targets}\n",
    "\n",
    "\n",
    "def create_module_dict(\n",
    "    *,\n",
    "    module,\n",
    "    n_per_class_list,\n",
    "    n_tries,\n",
    "    nb_knn,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "):\n",
    "    modules = {}\n",
    "    mapping = create_class_indices_mapping(train_labels)\n",
    "    for npc in n_per_class_list:\n",
    "        if npc < 0:  # Only one try needed when using the full data\n",
    "            full_module = module(\n",
    "                train_features=train_features,\n",
    "                train_labels=train_labels,\n",
    "                nb_knn=nb_knn,\n",
    "            )\n",
    "            modules[\"full\"] = ModuleDictWithForward({\"1\": full_module})\n",
    "            continue\n",
    "        all_tries = {}\n",
    "        for t in range(n_tries):\n",
    "            final_indices = filter_train(mapping, npc, seed=t)\n",
    "            k_list = list(set(nb_knn + [npc]))\n",
    "            k_list = sorted([el for el in k_list if el <= npc])\n",
    "            all_tries[str(t)] = module(\n",
    "                train_features=train_features[final_indices],\n",
    "                train_labels=train_labels[final_indices],\n",
    "                nb_knn=k_list,\n",
    "            )\n",
    "        modules[f\"{npc} per class\"] = ModuleDictWithForward(all_tries)\n",
    "\n",
    "    return ModuleDictWithForward(modules)\n",
    "\n",
    "\n",
    "def filter_train(mapping, n_per_class, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    final_indices = []\n",
    "    for k in mapping.keys():\n",
    "        index = torch.randperm(len(mapping[k]))[:n_per_class]\n",
    "        final_indices.append(mapping[k][index])\n",
    "    return torch.cat(final_indices).squeeze()\n",
    "\n",
    "\n",
    "def create_class_indices_mapping(labels):\n",
    "    unique_labels, inverse = torch.unique(labels, return_inverse=True)\n",
    "    mapping = {unique_labels[i]: (inverse == i).nonzero() for i in range(len(unique_labels))}\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleDictWithForward(torch.nn.ModuleDict):\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return {k: module(*args, **kwargs) for k, module in self._modules.items()}\n",
    "\n",
    "\n",
    "def eval_knn(\n",
    "    model,\n",
    "    dataset,\n",
    "    accuracy_averaging,\n",
    "    nb_knn,\n",
    "    temperature,\n",
    "    batch_size,\n",
    "    num_workers,\n",
    "    gather_on_cpu,\n",
    "    train_test_split_ratio=0.8,  # Add split ratio parameter\n",
    "    n_per_class_list=[-1],\n",
    "    n_tries=1,\n",
    "):\n",
    "    model = ModelWithNormalize(model)\n",
    "\n",
    "    logger.info(\"Extracting features for the dataset...\")\n",
    "    features, labels = extract_features(\n",
    "        model,\n",
    "        dataset,\n",
    "        batch_size,\n",
    "        num_workers,\n",
    "        gather_on_cpu=gather_on_cpu,\n",
    "    )\n",
    "    logger.info(f\"Dataset features created, shape {features.shape}.\")\n",
    "\n",
    "    # Compute the split index\n",
    "    split_idx = int(len(features) * train_test_split_ratio)\n",
    "\n",
    "    # Split into train and test\n",
    "    train_features, test_features = features[:split_idx], features[split_idx:]\n",
    "    train_labels, test_labels = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "\n",
    "\n",
    "    num_classes = int(train_labels.max() + 1)\n",
    "    print(\"Train num_classes\", num_classes)\n",
    "    metric_collection = build_topk_accuracy_metric(accuracy_averaging, num_classes=num_classes)\n",
    "\n",
    "    device = torch.cuda.current_device()\n",
    "    partial_module = partial(\n",
    "        KnnModule,\n",
    "        T=temperature,\n",
    "        device=device,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "    knn_module_dict = create_module_dict(\n",
    "        module=partial_module,\n",
    "        n_per_class_list=n_per_class_list,\n",
    "        n_tries=n_tries,\n",
    "        nb_knn=nb_knn,\n",
    "        train_features=train_features,\n",
    "        train_labels=train_labels,\n",
    "    )\n",
    "    postprocessors, metrics = {}, {}\n",
    "    for n_per_class, knn_module in knn_module_dict.items():\n",
    "        for t, knn_try in knn_module.items():\n",
    "            postprocessors = {\n",
    "                **postprocessors,\n",
    "                **{(n_per_class, t, k): DictKeysModule([n_per_class, t, k]) for k in knn_try.nb_knn},\n",
    "            }\n",
    "            metrics = {\n",
    "                **metrics,\n",
    "                **{\n",
    "                    (\n",
    "                        n_per_class,\n",
    "                        t,\n",
    "                        k,\n",
    "                    ): metric_collection.clone()\n",
    "                    for k in knn_try.nb_knn\n",
    "                },\n",
    "            }\n",
    "    model_with_knn = torch.nn.Sequential(model, knn_module_dict)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(test_features, test_labels),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    ")\n",
    "\n",
    "\n",
    "    # ============ evaluation ... ============\n",
    "    logger.info(\"Start the k-NN classification.\")\n",
    "    _, results_dict = evaluate(\n",
    "        model_with_knn,\n",
    "        test_loader,\n",
    "        postprocessors,\n",
    "        metrics,\n",
    "        device,\n",
    "    )\n",
    "\n",
    "    # Averaging the results over the n tries for each value of n_per_class\n",
    "    for n_per_class, knn_module in knn_module_dict.items():\n",
    "        first_try = list(knn_module.keys())[0]\n",
    "        k_list = knn_module[first_try].nb_knn\n",
    "        for k in k_list:\n",
    "            keys = results_dict[(n_per_class, first_try, k)].keys()  # keys are e.g. `top-1` and `top-5`\n",
    "            results_dict[(n_per_class, k)] = {\n",
    "                key: torch.mean(torch.stack([results_dict[(n_per_class, t, k)][key] for t in knn_module.keys()]))\n",
    "                for key in keys\n",
    "                if \"confmat\" not in key\n",
    "            }\n",
    "            if \"confmat\" in keys:\n",
    "                results_dict[(n_per_class, k)][\"confmat\"] = torch.sum(\n",
    "                    torch.stack([results_dict[(n_per_class, t, k)][\"confmat\"] for t in knn_module.keys()]),\n",
    "                    dim=0,\n",
    "                )\n",
    "\n",
    "            for t in knn_module.keys():\n",
    "                del results_dict[(n_per_class, t, k)]\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_knn_with_model(\n",
    "    model,\n",
    "    output_dir,\n",
    "    dataset_str=\"LMBD\",\n",
    "    nb_knn=(10, 20, 100, 200),\n",
    "    temperature=0.07,\n",
    "    autocast_dtype=torch.float,\n",
    "    accuracy_averaging=AccuracyAveraging.MEAN_ACCURACY,\n",
    "    transform=None,\n",
    "    gather_on_cpu=False,\n",
    "    batch_size=256,\n",
    "    num_workers=5,\n",
    "    n_per_class_list=[-1],\n",
    "    n_tries=1,\n",
    "    train_test_split_ratio=0.8  # Add split ratio here\n",
    "):\n",
    "    transform = transform or make_classification_eval_transform()\n",
    "\n",
    "    dataset = make_dataset(\n",
    "        dataset_str=dataset_str,\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "    with torch.cuda.amp.autocast(dtype=autocast_dtype):\n",
    "        results_dict_knn = eval_knn(\n",
    "            model=model,\n",
    "            dataset=dataset,\n",
    "            accuracy_averaging=accuracy_averaging,\n",
    "            nb_knn=nb_knn,\n",
    "            temperature=temperature,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            gather_on_cpu=gather_on_cpu,\n",
    "            train_test_split_ratio=train_test_split_ratio,  # Pass to eval_knn\n",
    "            n_per_class_list=n_per_class_list,\n",
    "            n_tries=n_tries,\n",
    "        )\n",
    "\n",
    "\n",
    "    results_dict, confmats_dict = {}, {}\n",
    "    if distributed.is_main_process():\n",
    "        for knn_ in results_dict_knn.keys():\n",
    "            metric_log_msg = f\"KNN {knn_[1]} classifier result: \"\n",
    "            for metric_name in results_dict_knn[knn_].keys():\n",
    "                metric_val = results_dict_knn[knn_][metric_name]\n",
    "                if \"confmat\" in metric_name:\n",
    "                    metric_val = metric_val.cpu()\n",
    "                    confmats_dict[knn_] = np.array(metric_val, dtype=np.uint)\n",
    "                else:\n",
    "                    metric_val = metric_val.item()\n",
    "                    results_dict[f\"{knn_} {metric_name}\"] = metric_val\n",
    "                    metric_log_msg += f\"{metric_name}: {metric_val:.4f} \"\n",
    "                if \"confmat\" not in metric_name:\n",
    "                    logger.info(metric_log_msg)\n",
    "\n",
    "    # save in ckpt dir\n",
    "    metrics_file_path = os.path.join(output_dir, \"results_eval_knn.json\")\n",
    "    with open(metrics_file_path, \"a\") as f:\n",
    "        for k, v in results_dict.items():\n",
    "            f.write(json.dumps({k: v}) + \"\\n\")\n",
    "\n",
    "    confmat_file_path = os.path.join(output_dir, \"confmats_knn\")\n",
    "    os.makedirs(confmat_file_path, exist_ok=True)\n",
    "    np.save(confmat_file_path + \".npy\", confmats_dict)\n",
    "    for k, v in confmats_dict.items():\n",
    "        knn_nb = re.search(\"[0-9]+\", str(k))\n",
    "        if knn_nb:\n",
    "            knn_nb = knn_nb.group(0)\n",
    "        else:\n",
    "            knn_nb = k\n",
    "        np.save(\n",
    "            os.path.join(confmat_file_path, f\"knn_{knn_nb}\"),\n",
    "            v,\n",
    "        )\n",
    "\n",
    "    if distributed.is_enabled():\n",
    "        torch.distributed.barrier()\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print(\"args.output_dir\", args)\n",
    "    model, autocast_dtype = setup_and_build_model(args, do_eval=True)\n",
    "\n",
    "\n",
    "    eval_knn_with_model(\n",
    "        model=model,\n",
    "        output_dir=args.output_dir_ckpt,\n",
    "        dataset_str=args.dataset_str,\n",
    "        #val_dataset_str=args.val_dataset_str,\n",
    "        nb_knn=args.nb_knn,\n",
    "        temperature=args.temperature,\n",
    "        autocast_dtype=autocast_dtype,\n",
    "        accuracy_averaging=AccuracyAveraging.MEAN_ACCURACY,\n",
    "        transform=None,\n",
    "        gather_on_cpu=args.gather_on_cpu,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        n_per_class_list=args.n_per_class_list,\n",
    "        n_tries=args.n_tries,\n",
    "    )\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.output_dir Namespace(model='/home/nick/Downloads/dinov2_vits14_pretrain.pth', output_dir_ckpt='/home/nick/Documents/ws24', batch_size=256, num_workers=1, dataset_str='LMDB:split=all:root=/home/nick/Downloads/113201/FlowCamNet/imgs_lmdbs/:extra=*', nb_knn=[10, 20, 100, 200], temperature=0.07, gather_on_cpu=True, n_per_class_list=[-1], n_tries=1, run_name='knn_run', num_nodes=1, config_file='/home/nick/Documents/ws24/Masterproject-plankton-dinov2/dinov2/configs/eval/vits14_pretrain.yaml', opts=None)\n",
      "args.run_name  knn_run_14112024_113539_vit_small\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error initializing torch.distributed using env:// rendezvous: environment variable RANK expected, but not set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m args \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mNamespace(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs_dict)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Check if the process group is already initialized before calling main\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(args):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs.output_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m, args)\n\u001b[0;32m----> 3\u001b[0m     model, autocast_dtype \u001b[38;5;241m=\u001b[39m \u001b[43msetup_and_build_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     eval_knn_with_model(\n\u001b[1;32m      7\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      8\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39moutput_dir_ckpt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m         n_tries\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mn_tries,\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ws24/Masterproject-plankton-dinov2/dinov2/eval/setup.py:80\u001b[0m, in \u001b[0;36msetup_and_build_model\u001b[0;34m(args, do_eval)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_and_build_model\u001b[39m(args, do_eval: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, torch\u001b[38;5;241m.\u001b[39mdtype]:\n\u001b[1;32m     79\u001b[0m     cudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_model_for_eval(config, args\u001b[38;5;241m.\u001b[39mpretrained_weights)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m do_eval:\n",
      "File \u001b[0;32m~/Documents/ws24/Masterproject-plankton-dinov2/dinov2/utils/config.py:86\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(args, do_eval)\u001b[0m\n\u001b[1;32m     83\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39moutput_dir, args\u001b[38;5;241m.\u001b[39mrun_name)\n\u001b[1;32m     85\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(cfg\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39moutput_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 86\u001b[0m \u001b[43mdefault_setup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m apply_scaling_rules_to_cfg(cfg)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distributed\u001b[38;5;241m.\u001b[39mis_main_process():\n",
      "File \u001b[0;32m~/Documents/ws24/Masterproject-plankton-dinov2/dinov2/utils/config.py:49\u001b[0m, in \u001b[0;36mdefault_setup\u001b[0;34m(args, output_dir, do_eval)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_setup\u001b[39m(args, output_dir, do_eval: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(args, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     51\u001b[0m     rank \u001b[38;5;241m=\u001b[39m distributed\u001b[38;5;241m.\u001b[39mget_global_rank()\n",
      "File \u001b[0;32m~/Documents/ws24/Masterproject-plankton-dinov2/dinov2/distributed/__init__.py:223\u001b[0m, in \u001b[0;36menable\u001b[0;34m(set_cuda_current_device, overwrite, allow_nccl_timeout, num_nodes)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable\u001b[39m(\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    210\u001b[0m     set_cuda_current_device: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     num_nodes: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    214\u001b[0m ):\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Enable distributed mode\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m        overwrite: If True, overwrites already set variables. Else fails.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     torch_env \u001b[38;5;241m=\u001b[39m \u001b[43m_TorchDistributedEnvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSLURM_JOB_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    226\u001b[0m         torch_env\u001b[38;5;241m.\u001b[39m_set_from_slurm_env()\n",
      "File \u001b[0;32m~/Documents/ws24/Masterproject-plankton-dinov2/dinov2/distributed/__init__.py:142\u001b[0m, in \u001b[0;36m_TorchDistributedEnvironment.__init__\u001b[0;34m(self, num_nodes)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_nodes: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnccl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     dist\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch dist initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dinov2_2/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:86\u001b[0m, in \u001b[0;36m_time_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     85\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[0;32m---> 86\u001b[0m     func_return \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns() \u001b[38;5;241m-\u001b[39m t1\n\u001b[1;32m     89\u001b[0m     msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dinov2_2/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:1177\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1174\u001b[0m     rendezvous_iterator \u001b[38;5;241m=\u001b[39m rendezvous(\n\u001b[1;32m   1175\u001b[0m         init_method, rank, world_size, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1176\u001b[0m     )\n\u001b[0;32m-> 1177\u001b[0m     store, rank, world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrendezvous_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m     store\u001b[38;5;241m.\u001b[39mset_timeout(timeout)\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dinov2_2/lib/python3.10/site-packages/torch/distributed/rendezvous.py:234\u001b[0m, in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(query_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43m_get_env_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRANK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworld_size\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m query_dict:\n\u001b[1;32m    237\u001b[0m     world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(query_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworld_size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/dinov2_2/lib/python3.10/site-packages/torch/distributed/rendezvous.py:219\u001b[0m, in \u001b[0;36m_env_rendezvous_handler.<locals>._get_env_or_raise\u001b[0;34m(env_var)\u001b[0m\n\u001b[1;32m    217\u001b[0m env_val \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(env_var, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env_val:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _env_error(env_var)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_val\n",
      "\u001b[0;31mValueError\u001b[0m: Error initializing torch.distributed using env:// rendezvous: environment variable RANK expected, but not set"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch.distributed as dist\n",
    "import os\n",
    "\n",
    "# Set environment variables for distributed initialization\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "# Define a dictionary to simulate command-line arguments\n",
    "args_dict = {\n",
    "    \"model\": \"/home/nick/Downloads/dinov2_vits14_pretrain.pth\",\n",
    "    \"output_dir_ckpt\": \"/home/nick/Documents/ws24\",\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": 1,\n",
    "    \"dataset_str\": \"LMDB:split=all:root=/home/nick/Downloads/113201/FlowCamNet/imgs_lmdbs/:extra=*\",\n",
    "    \"nb_knn\": [10, 20, 100, 200],\n",
    "    \"temperature\": 0.07,\n",
    "    \"gather_on_cpu\": True,\n",
    "    \"n_per_class_list\": [-1],\n",
    "    \"n_tries\": 1,\n",
    "    \"run_name\": \"knn_run\",\n",
    "    \"num_nodes\": 1,\n",
    "    \"config_file\": \"/home/nick/Documents/ws24/Masterproject-plankton-dinov2/dinov2/configs/eval/vits14_pretrain.yaml\",\n",
    "    \"opts\": None,\n",
    "}\n",
    "\n",
    "# Convert the dictionary to an argparse.Namespace object\n",
    "args = argparse.Namespace(**args_dict)\n",
    "\n",
    "# Check if the process group is already initialized before calling main\n",
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
