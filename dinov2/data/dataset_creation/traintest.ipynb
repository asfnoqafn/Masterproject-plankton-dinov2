{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtf\n",
      "TOTAL #images 301247 FROM /home/nick/Downloads/113201/FlowCamNet/imgs\n",
      "100%|█████████████████████████████████| 301247/301247 [02:05<00:00, 2391.53it/s]\n",
      "Finished importing from /home/nick/Downloads/113201/FlowCamNet/imgs and subdirectories, saved at: /home/nick/Documents/ws24/lmdb/bigger/ZooScan_imgs\n",
      "Finished importing from /home/nick/Downloads/113201/FlowCamNet/imgs and subdirectories, saved at: /home/nick/Documents/ws24/lmdb/bigger/ZooScan_imgs\n"
     ]
    }
   ],
   "source": [
    "!python save_cpics_pngs_to_lmdb.py --dataset_path=\"/home/nick/Downloads/113201/FlowCamNet/imgs\" --lmdb_dir_name=\"/home/nick/Documents/ws24/lmdb/bigger/\" --min_size=128 --dataset_name=\"ZooScan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ZooScan \n",
    "\n",
    "60115 imgs remain if only one of the dims has to be > 128, \n",
    "13k imgs if both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify correct labels were assigned to correct img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in LMDB: 60115\n",
      "Number of labels in LMDB: 60115\n",
      "Verified Image Key: Acantharia_164727498.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_0.png\n",
      "Verified Image Key: Acantharia_164727514.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_1.png\n",
      "Verified Image Key: Acantharia_164727544.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_2.png\n",
      "Verified Image Key: Acantharia_164728219.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_3.png\n",
      "Verified Image Key: Acantharia_164901027.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_4.png\n",
      "Verified Image Key: Acantharia_164966858.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_5.png\n",
      "Verified Image Key: Acantharia_164969210.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_6.png\n",
      "Verified Image Key: Acantharia_164970897.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_7.png\n",
      "Verified Image Key: Acantharia_164971673.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_8.png\n",
      "Verified Image Key: Acantharia_164972466.png, Label: Acantharia, Saved to: ./debug_output/debug_Acantharia_9.png\n",
      "Verification complete. Images saved to ./debug_output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "\n",
    "# Set paths to your LMDB directories\n",
    "LMDB_IMGS_PATH = \"/home/nick/Documents/ws24/lmdb/bigger/ZooScan_imgs\" #\"/home/nick/Documents/ws24/out/TEST_imgs\" #\n",
    "LMDB_LABELS_PATH = \"/home/nick/Documents/ws24/lmdb/bigger/ZooScan_labels\" #\"/home/nick/Documents/ws24/out/TEST_labels\"\n",
    "DEBUG_OUTPUT_DIR = \"./debug_output\"\n",
    "\n",
    "\n",
    "os.makedirs(DEBUG_OUTPUT_DIR, exist_ok=True)\n",
    "def count_entries(lmdb_path):\n",
    "    env = lmdb.open(lmdb_path, readonly=True)\n",
    "    \n",
    "    with env.begin() as txn:\n",
    "        cursor = txn.cursor()\n",
    "        count = 0\n",
    "        for key, _ in cursor:\n",
    "            count += 1\n",
    "        \n",
    "    env.close()\n",
    "    \n",
    "    return count\n",
    "\n",
    "def load_and_verify_lmdb(lmdb_imgs_path, lmdb_labels_path, debug_output_dir, max_images=10):\n",
    "    num_images = count_entries(lmdb_imgs_path)\n",
    "    num_labels = count_entries(lmdb_labels_path)\n",
    "    \n",
    "    print(f\"Number of images in LMDB: {num_images}\")\n",
    "    print(f\"Number of labels in LMDB: {num_labels}\")\n",
    "\n",
    "    env_imgs = lmdb.open(lmdb_imgs_path, readonly=True)\n",
    "    env_labels = lmdb.open(lmdb_labels_path, readonly=True)\n",
    "\n",
    "    with env_imgs.begin() as txn_imgs, env_labels.begin() as txn_labels:\n",
    "        cursor_imgs = txn_imgs.cursor()\n",
    "        cursor_labels = txn_labels.cursor()        \n",
    "        count = 0\n",
    "        for (img_key, img_value), (label_key, label_value) in zip(cursor_imgs, cursor_labels):\n",
    "            img_decoded = iio.imread(img_value)\n",
    "            \n",
    "            label_decoded = label_value.decode(\"utf-8\")\n",
    "            \n",
    "            # Save the image for verification\n",
    "            output_path = os.path.join(debug_output_dir, f\"debug_{label_decoded}_{count}.png\")\n",
    "            iio.imwrite(output_path, img_decoded)\n",
    "            \n",
    "            print(f\"Verified Image Key: {img_key.decode('utf-8')}, Label: {label_decoded}, Saved to: {output_path}\")\n",
    "            \n",
    "            count += 1\n",
    "            if count >= max_images:  # dont want to save all images\n",
    "                break\n",
    "\n",
    "    env_imgs.close()\n",
    "    env_labels.close()\n",
    "    print(f\"Verification complete. Images saved to {debug_output_dir}\")\n",
    "\n",
    "load_and_verify_lmdb(LMDB_IMGS_PATH, LMDB_LABELS_PATH, DEBUG_OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available memory: 23355.890625 MB\n",
      "Available memory: 23355.890625 MB\n",
      "Loading dataset: ZooScan_imgs\n",
      "/home/nick/Documents/ws24/lmdb/ZooScan_imgs\n",
      "Loading dataset: ZooScan_labels\n",
      "/home/nick/Documents/ws24/lmdb/ZooScan_labels\n",
      "Total data loaded: 13212 images and 13212 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10569/10569 [00:00<00:00, 132082.32it/s]\n",
      "100%|██████████| 2643/2643 [00:00<00:00, 140572.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing and saving datasets to /home/nick/Documents/ws24/out\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_available_memory():\n",
    "    \"\"\"Get available memory and return a safe allocation size for LMDB.\"\"\"\n",
    "    available_memory = psutil.virtual_memory().available\n",
    "    print(f\"Available memory: {available_memory / 1024 / 1024} MB\")\n",
    "    return int(available_memory * 0.75) \n",
    "\n",
    "\n",
    "MAP_SIZE_IMG = get_available_memory()\n",
    "MAP_SIZE_META = int(get_available_memory()*0.1)\n",
    "\n",
    "def load_lmdb_data(lmdb_path):\n",
    "    \"\"\"\n",
    "    Loads data from an LMDB file and returns it as a list of (key, value) pairs.\n",
    "    \"\"\"\n",
    "    env = lmdb.open(lmdb_path, readonly=True)\n",
    "    data = []\n",
    "    with env.begin() as txn:\n",
    "        cursor = txn.cursor()\n",
    "        for key, value in cursor:\n",
    "            data.append((key, value))\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_lmdb_data(lmdb_path_img, lmdb_path_label, img_data, label_data):\n",
    "    \"\"\"\n",
    "    Saves images and labels to LMDB, no decoding and reencoding.\n",
    "    \"\"\"\n",
    "    env_imgs = lmdb.open(lmdb_path_img, map_size=MAP_SIZE_IMG)\n",
    "    env_labels = lmdb.open(lmdb_path_label, map_size=MAP_SIZE_META)\n",
    "        \n",
    "    with (\n",
    "        env_imgs.begin(write=True) as txn_imgs,\n",
    "        env_labels.begin(write=True) as txn_labels,\n",
    "    ):\n",
    "        # Iterate through img_data and label_data, assuming each contains (key, data)\n",
    "        for (img_key, img_encoded), (label_key, label) in tqdm(zip(img_data, label_data), total=len(img_data)):\n",
    "            # Ensure keys match (img_key should be the same in both img_data and label_data)\n",
    "            if img_key != label_key:\n",
    "                print(f\"Warning: Mismatched keys! img_key: {img_key}, label_key: {label_key}\")\n",
    "                continue  # Skip if keys don't match\n",
    "\n",
    "            txn_imgs.put(img_key, img_encoded)  \n",
    "            txn_labels.put(label_key, label)\n",
    " \n",
    "    env_imgs.close()\n",
    "    env_labels.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_all_datasets(main_folder):\n",
    "    \"\"\"\n",
    "    Load all datasets in the given folder and return combined image and label data.\n",
    "    \"\"\"\n",
    "    img_data = []\n",
    "    label_data = []\n",
    "    \n",
    "    for dataset in os.listdir(main_folder):\n",
    "        print(f\"Loading dataset: {dataset}\")\n",
    "        dataset_path = os.path.join(main_folder, dataset)\n",
    "        print(dataset_path)\n",
    "        if dataset_path.endswith(\"_imgs\"):\n",
    "            img_data.extend(load_lmdb_data(dataset_path))\n",
    "        elif dataset_path.endswith(\"_labels\"):\n",
    "            label_data.extend(load_lmdb_data(dataset_path))\n",
    "        else:\n",
    "            print(f\"Skipping {dataset_path}\")\n",
    "            print(\"we are fucked if this contains a valid path\")\n",
    "                \n",
    "    return img_data, label_data\n",
    "\n",
    "def split_and_save_data(main_folder, output_folder, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Loads all datasets, splits the data into train and test, and saves them in the output folder.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load all datasets\n",
    "    img_data, label_data = load_all_datasets(main_folder)\n",
    "    \n",
    "    print(f\"Total data loaded: {len(img_data)} images and {len(label_data)} labels.\")\n",
    "\n",
    "    # Split dataset into train and test\n",
    "    train_imgs, test_imgs = train_test_split(img_data, test_size=test_size,shuffle=True, random_state=43)\n",
    "    train_labels, test_labels = train_test_split(label_data, test_size=test_size,shuffle=True, random_state=43)\n",
    "\n",
    "    # Save the split data to LMDB\n",
    "    save_lmdb_data(os.path.join(output_folder, \"TRAIN_imgs\"), os.path.join(output_folder, \"TRAIN_labels\"), train_imgs, train_labels)\n",
    "    save_lmdb_data(os.path.join(output_folder, \"TEST_imgs\"), os.path.join(output_folder, \"TEST_labels\"), test_imgs, test_labels)\n",
    "\n",
    "    print(f\"Finished processing and saving datasets to {output_folder}\")\n",
    "\n",
    "split_and_save_data(main_folder=\"/home/nick/Documents/ws24/lmdb\", output_folder=\"/home/nick/Documents/ws24/out\", test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify balanced train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification for TEST dataset:\n",
      "Number of images in LMDB: 2643\n",
      "Number of labels in LMDB: 2643\n",
      "Number of unique classes: 49\n",
      "\n",
      "Verification for TRAIN dataset:\n",
      "Number of images in LMDB: 10569\n",
      "Number of labels in LMDB: 10569\n",
      "Number of unique classes: 66\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "os.makedirs(\"./debug_output\", exist_ok=True)\n",
    "\n",
    "def count_entries(lmdb_path):\n",
    "    env = lmdb.open(lmdb_path, readonly=True)\n",
    "    \n",
    "    with env.begin() as txn:\n",
    "        cursor = txn.cursor()\n",
    "        count = 0\n",
    "        for key, _ in cursor:\n",
    "            count += 1\n",
    "    env.close()\n",
    "    \n",
    "    return count\n",
    "\n",
    "def load_and_verify_lmdb(lmdb_imgs_path, lmdb_labels_path, debug_output_dir, max_images=10):\n",
    "\n",
    "    num_images = count_entries(lmdb_imgs_path)\n",
    "    num_labels = count_entries(lmdb_labels_path)\n",
    "    \n",
    "    print(f\"Number of images in LMDB: {num_images}\")\n",
    "    print(f\"Number of labels in LMDB: {num_labels}\")\n",
    "\n",
    "    env_imgs = lmdb.open(lmdb_imgs_path, readonly=True)\n",
    "    env_labels = lmdb.open(lmdb_labels_path, readonly=True)\n",
    "\n",
    "    label_counter = Counter()  # Counter to track label occurrences\n",
    "    \n",
    "    with env_imgs.begin() as txn_imgs, env_labels.begin() as txn_labels:\n",
    "        cursor_imgs = txn_imgs.cursor()\n",
    "        cursor_labels = txn_labels.cursor()        \n",
    "        count = 0\n",
    "        for (img_key, img_value), (label_key, label_value) in zip(cursor_imgs, cursor_labels):\n",
    "            \n",
    "            label_decoded = label_value.decode(\"utf-8\")\n",
    "            \n",
    "            label_counter[label_decoded] += 1\n",
    "            \n",
    "    env_imgs.close()\n",
    "    env_labels.close()\n",
    "    \n",
    "    print(f\"Number of unique classes: {len(label_counter)}\")\n",
    "    #for label, count in label_counter.items():\n",
    "    #    print(f\"{label}: {count} occurrences\")\n",
    "    \n",
    "\n",
    "print(\"Verification for TEST dataset:\")\n",
    "load_and_verify_lmdb(\"/home/nick/Documents/ws24/out/TEST_imgs\" , \"/home/nick/Documents/ws24/out/TEST_labels\" ,\"./debug_output\")\n",
    "print(\"\\nVerification for TRAIN dataset:\")\n",
    "load_and_verify_lmdb(\"/home/nick/Documents/ws24/out/TRAIN_imgs\" , \"/home/nick/Documents/ws24/out/TRAIN_labels\" ,\"./debug_output\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
