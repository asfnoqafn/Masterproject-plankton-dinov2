{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import psutil\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "\n",
    "def image_to_byte_array(image: Image) -> bytes:\n",
    "    \"\"\"Convert a PIL image to a byte array.\"\"\"\n",
    "    img_byte_arr = BytesIO()\n",
    "    image.save(img_byte_arr, format='JPEG')\n",
    "    return img_byte_arr.getvalue()\n",
    "\n",
    "def get_available_memory():\n",
    "    \"\"\"Get available memory and return a safe allocation size for LMDB.\"\"\"\n",
    "    available_memory = psutil.virtual_memory().available\n",
    "    print(f\"Available memory: {available_memory / 1024 / 1024} MB\")\n",
    "    return int(available_memory * 0.5)  # Use 50% of available memory as a safe map_size\n",
    "\n",
    "def create_separate_lmdbs_in_batches(input_folder, output_folder, batch_size=500):\n",
    "    # Set available memory for LMDB map_size\n",
    "    map_size = get_available_memory()\n",
    "\n",
    "    idx = 0\n",
    "    batch_num = 0\n",
    "\n",
    "    # Traverse through each class folder, assigning a label based on position\n",
    "    for label, class_name in enumerate(sorted(os.listdir(input_folder))):\n",
    "        class_path = os.path.join(input_folder, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for img_name in sorted(os.listdir(class_path)):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            if not img_path.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "\n",
    "            # Load the image and convert it to bytes\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_bytes = image_to_byte_array(img)\n",
    "\n",
    "            # If starting a new batch, create new LMDB environments for images and labels\n",
    "            if idx % batch_size == 0:\n",
    "                if idx > 0:\n",
    "                    # Close previous batch LMDB files\n",
    "                    img_lmdb_env.close()\n",
    "                    label_lmdb_env.close()\n",
    "                    print(f\"Batch {batch_num} saved with images and labels.\")\n",
    "\n",
    "                # Define batch LMDB file paths\n",
    "                batch_start = idx\n",
    "                batch_end = idx + batch_size - 1\n",
    "                img_lmdb_path = os.path.join(output_folder, f\"img{batch_start}-{batch_end}_imgs\")\n",
    "                label_lmdb_path = os.path.join(output_folder, f\"img{batch_start}-{batch_end}_labels\")\n",
    "                os.makedirs(os.path.dirname(img_lmdb_path), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(label_lmdb_path), exist_ok=True)\n",
    "\n",
    "                # Open new LMDB environments for the current batch\n",
    "                img_lmdb_env = lmdb.open(img_lmdb_path, map_size=map_size)\n",
    "                label_lmdb_env = lmdb.open(label_lmdb_path, map_size=map_size)\n",
    "                batch_num += 1\n",
    "\n",
    "            # Store image bytes in img_lmdb and label in label_lmdb\n",
    "            with img_lmdb_env.begin(write=True) as img_txn, label_lmdb_env.begin(write=True) as label_txn:\n",
    "                img_txn.put(f\"{idx}\".encode(), img_bytes)\n",
    "                label_txn.put(f\"{idx}\".encode(), pickle.dumps(label))\n",
    "                \n",
    "            idx += 1\n",
    "\n",
    "    # Close the final batch\n",
    "    img_lmdb_env.close()\n",
    "    label_lmdb_env.close()\n",
    "    print(f\"Final batch {batch_num} saved with images and labels.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"/home/nick/Documents/ws24/lmdb/\"\n",
    "output_folder = \"/home/nick/Documents/ws24/lmdb/train\"\n",
    "create_separate_lmdbs_in_batches(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def byte_array_to_image(byte_array):\n",
    "    \"\"\"Convert a byte array back to a PIL image.\"\"\"\n",
    "    img_byte_arr = BytesIO(byte_array)\n",
    "    return Image.open(img_byte_arr)\n",
    "\n",
    "def load_data_from_lmdb(lmdb_path):\n",
    "    \"\"\"Load images and labels from an LMDB file.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    with lmdb.open(lmdb_path, readonly=True) as env:\n",
    "        with env.begin() as txn:\n",
    "            cursor = txn.cursor()\n",
    "            for key, value in cursor:\n",
    "                if 'imgs' in lmdb_path:\n",
    "                    images.append((key.decode(), value))  # Store byte array for images\n",
    "                elif 'labels' in lmdb_path:\n",
    "                    labels.append((key.decode(), pickle.loads(value)))  # Store label as int\n",
    "    return images, labels\n",
    "\n",
    "def save_images_and_labels(data, folder_path, subfolder_name):\n",
    "    \"\"\"Save images and labels to specified folders.\"\"\"\n",
    "    img_folder = os.path.join(folder_path, f\"{subfolder_name}_images\")\n",
    "    label_folder = os.path.join(folder_path, f\"{subfolder_name}_labels\")\n",
    "    os.makedirs(img_folder, exist_ok=True)\n",
    "    os.makedirs(label_folder, exist_ok=True)\n",
    "\n",
    "    for idx, (key, img_bytes) in enumerate(data['images']):\n",
    "        # Save image\n",
    "        image = byte_array_to_image(img_bytes)\n",
    "        image_path = os.path.join(img_folder, f\"{key}.jpg\")\n",
    "        image.save(image_path, format='JPEG')\n",
    "\n",
    "        # Save label\n",
    "        label = data['labels'][idx][1]  # Get corresponding label using the same index\n",
    "        label_path = os.path.join(label_folder, f\"{key}.pkl\")\n",
    "        with open(label_path, 'wb') as f:\n",
    "            pickle.dump(label, f)\n",
    "\n",
    "def process_lmdb_files(input_folder, output_folder, test_size=0.2):\n",
    "    # Get all LMDB files for images and labels\n",
    "    lmdb_files = sorted([os.path.join(input_folder, f) for f in os.listdir(input_folder) if 'img' in f])\n",
    "    \n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Load images and labels from LMDB batches\n",
    "    for lmdb_file in lmdb_files:\n",
    "        images, labels = load_data_from_lmdb(lmdb_file)\n",
    "        if 'imgs' in lmdb_file:\n",
    "            all_images.extend(images)\n",
    "        elif 'labels' in lmdb_file:\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # Ensure images and labels are aligned\n",
    "    all_images.sort(key=lambda x: int(x[0]))  # Sort by key to align with labels\n",
    "    all_labels.sort(key=lambda x: int(x[0]))\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "        all_images, all_labels, shuffle= True, test_size=test_size, random_state=42\n",
    "    )\n",
    "\n",
    "    # Save training and testing sets\n",
    "    save_images_and_labels({'images': train_images, 'labels': train_labels}, output_folder, 'train')\n",
    "    save_images_and_labels({'images': test_images, 'labels': test_labels}, output_folder, 'test')\n",
    "    print(\"Data has been split and saved into train and test folders.\")\n",
    "\n",
    "# Set paths\n",
    "input_folder = \"/home/nick/Documents/ws24/lmdb/test1\"\n",
    "output_folder = \"/home/nick/Documents/ws24/lmdb/out1\"\n",
    "\n",
    "# Process and split data\n",
    "process_lmdb_files(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x71d602541cb0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m all_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lmdb_path \u001b[38;5;129;01min\u001b[39;00m lmdb_paths:\n\u001b[0;32m---> 50\u001b[0m     all_data\u001b[38;5;241m.\u001b[39mextend(\u001b[43mload_lmdb_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlmdb_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Split data into class-balanced train and test sets\u001b[39;00m\n\u001b[1;32m     53\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m split_data(all_data, test_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mload_lmdb_data\u001b[0;34m(lmdb_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m cursor \u001b[38;5;241m=\u001b[39m txn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m cursor:\n\u001b[0;32m---> 16\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust if images are stored differently\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     label \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Adjust if label extraction is different\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend((image, label))\n",
      "File \u001b[0;32m~/anaconda3/envs/dinov2_2/lib/python3.10/site-packages/PIL/Image.py:3498\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3496\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3497\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3498\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x71d602541cb0>"
     ]
    }
   ],
   "source": [
    "import lmdb\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def load_lmdb_data(lmdb_path):\n",
    "    \"\"\"Load images and labels from LMDB file.\"\"\"\n",
    "    data = []\n",
    "    env = lmdb.open(lmdb_path, readonly=True, lock=False)\n",
    "    with env.begin() as txn:\n",
    "        cursor = txn.cursor()\n",
    "        for key, value in cursor:\n",
    "            image = Image.open(BytesIO(value))  # Adjust if images are stored differently\n",
    "            \n",
    "            label = key.decode(\"utf-8\").split(\"_\")[1]  # Adjust if label extraction is different\n",
    "            data.append((image, label))\n",
    "    return data\n",
    "\n",
    "def split_data(data, test_ratio=0.2):\n",
    "    \"\"\"Split data into train and test sets with a class-balanced split.\"\"\"\n",
    "    train_data, test_data = [], []\n",
    "    classes = set([label for _, label in data])\n",
    "    for cls in classes:\n",
    "        cls_data = [(img, label) for img, label in data if label == cls]\n",
    "        train, test = train_test_split(cls_data, test_size=test_ratio, random_state=42)\n",
    "        train_data.extend(train)\n",
    "        test_data.extend(test)\n",
    "    return train_data, test_data\n",
    "\n",
    "def save_to_lmdb(data, lmdb_path):\n",
    "    \"\"\"Save a list of (image, label) pairs to an LMDB database.\"\"\"\n",
    "    env = lmdb.open(lmdb_path, map_size=1e12)  # Adjust map_size as needed\n",
    "    with env.begin(write=True) as txn:\n",
    "        for i, (img, label) in enumerate(data):\n",
    "            img_byte_arr = BytesIO()\n",
    "            img.save(img_byte_arr, format='PNG')\n",
    "            key = f\"{i}_{label}\".encode(\"utf-8\")  # Key format as needed\n",
    "            txn.put(key, img_byte_arr.getvalue())\n",
    "    env.close()\n",
    "\n",
    "# Example usage:\n",
    "lmdb_paths = [\"/home/nick/Documents/ws24/lmdb/\"]\n",
    "output_path = \"/home/nick/Documents/ws24/lmdb/out\" # Define your desired output path\n",
    "\n",
    "# Load data from each LMDB file\n",
    "all_data = []\n",
    "for lmdb_path in lmdb_paths:\n",
    "    all_data.extend(load_lmdb_data(lmdb_path))\n",
    "\n",
    "# Split data into class-balanced train and test sets\n",
    "train_data, test_data = split_data(all_data, test_ratio=0.2)\n",
    "\n",
    "# Save train and test data to LMDB databases\n",
    "save_to_lmdb(train_data, os.path.join(output_path, \"train_images.lmdb\"))\n",
    "save_to_lmdb(test_data, os.path.join(output_path, \"test_images.lmdb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtf\n",
      "TOTAL #images 301247 FROM /home/nick/Downloads/113201/FlowCamNet/imgs\n",
      "100%|█████████████████████████████████| 301247/301247 [01:47<00:00, 2804.08it/s]\n",
      "Finished importing from /home/nick/Downloads/113201/FlowCamNet/imgs and subdirectories, saved at: /home/nick/Documents/ws24/lmdb/ZooScan_imgs\n",
      "Finished importing from /home/nick/Downloads/113201/FlowCamNet/imgs and subdirectories, saved at: /home/nick/Documents/ws24/lmdb/ZooScan_imgs\n"
     ]
    }
   ],
   "source": [
    "!python save_cpics_pngs_to_lmdb.py --dataset_path=\"/home/nick/Downloads/113201/FlowCamNet/imgs\" --lmdb_dir_name=\"/home/nick/Documents/ws24/lmdb/\" --min_size=128 --dataset_name=\"ZooScan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in LMDB: 2643\n",
      "Number of labels in LMDB: 2643\n",
      "Verified Image Key: Appendicularia_164794272.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_0.png\n",
      "Verified Image Key: Appendicularia_164794416.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_1.png\n",
      "Verified Image Key: Appendicularia_164794457.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_2.png\n",
      "Verified Image Key: Appendicularia_164794639.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_3.png\n",
      "Verified Image Key: Appendicularia_164794665.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_4.png\n",
      "Verified Image Key: Appendicularia_164794801.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_5.png\n",
      "Verified Image Key: Appendicularia_164794863.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_6.png\n",
      "Verified Image Key: Appendicularia_164931190.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_7.png\n",
      "Verified Image Key: Appendicularia_164931200.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_8.png\n",
      "Verified Image Key: Appendicularia_165049875.png, Label: Appendicularia, Saved to: ./debug_output/debug_Appendicularia_9.png\n",
      "Verification complete. Images saved to ./debug_output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "\n",
    "# Set paths to your LMDB directories\n",
    "LMDB_IMGS_PATH = \"/home/nick/Documents/ws24/out/TEST_imgs\" #\"/home/nick/Documents/ws24/lmdb/ZooScan_imgs\"\n",
    "LMDB_LABELS_PATH = \"/home/nick/Documents/ws24/out/TEST_labels\" #\"/home/nick/Documents/ws24/lmdb/ZooScan_labels\"\n",
    "DEBUG_OUTPUT_DIR = \"./debug_output\"\n",
    "\n",
    "# Ensure the debug output directory exists\n",
    "os.makedirs(DEBUG_OUTPUT_DIR, exist_ok=True)\n",
    "def count_entries(lmdb_path):\n",
    "    # Open the LMDB environment\n",
    "    env = lmdb.open(lmdb_path, readonly=True)\n",
    "    \n",
    "    with env.begin() as txn:\n",
    "        # Get all the keys in the database\n",
    "        cursor = txn.cursor()\n",
    "        \n",
    "        count = 0\n",
    "        for key, _ in cursor:\n",
    "            count += 1\n",
    "        \n",
    "    env.close()\n",
    "    \n",
    "    return count\n",
    "\n",
    "def load_and_verify_lmdb(lmdb_imgs_path, lmdb_labels_path, debug_output_dir, max_images=10):\n",
    "    # Open the LMDB databases\n",
    "    num_images = count_entries(lmdb_imgs_path)\n",
    "    num_labels = count_entries(lmdb_labels_path)\n",
    "    \n",
    "    print(f\"Number of images in LMDB: {num_images}\")\n",
    "    print(f\"Number of labels in LMDB: {num_labels}\")\n",
    "\n",
    "    env_imgs = lmdb.open(lmdb_imgs_path, readonly=True)\n",
    "    env_labels = lmdb.open(lmdb_labels_path, readonly=True)\n",
    "\n",
    "    with env_imgs.begin() as txn_imgs, env_labels.begin() as txn_labels:\n",
    "        cursor_imgs = txn_imgs.cursor()\n",
    "        cursor_labels = txn_labels.cursor()        \n",
    "        count = 0\n",
    "        for (img_key, img_value), (label_key, label_value) in zip(cursor_imgs, cursor_labels):\n",
    "            # Decode the image\n",
    "            img_decoded = iio.imread(img_value)  # Read the encoded image\n",
    "            \n",
    "            # Decode the label\n",
    "            label_decoded = label_value.decode(\"utf-8\")\n",
    "            \n",
    "            # Save the image for verification\n",
    "            output_path = os.path.join(debug_output_dir, f\"debug_{label_decoded}_{count}.png\")\n",
    "            iio.imwrite(output_path, img_decoded)\n",
    "            \n",
    "            print(f\"Verified Image Key: {img_key.decode('utf-8')}, Label: {label_decoded}, Saved to: {output_path}\")\n",
    "            \n",
    "            count += 1\n",
    "            if count >= max_images:  # Limit the number of images to verify\n",
    "                break\n",
    "\n",
    "    # Close the LMDB environments\n",
    "    env_imgs.close()\n",
    "    env_labels.close()\n",
    "    print(f\"Verification complete. Images saved to {debug_output_dir}\")\n",
    "\n",
    "# Run the verification script\n",
    "load_and_verify_lmdb(LMDB_IMGS_PATH, LMDB_LABELS_PATH, DEBUG_OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available memory: 22124.16015625 MB\n",
      "Available memory: 22124.16015625 MB\n",
      "Loading dataset: ZooScan_imgs\n",
      "/home/nick/Documents/ws24/lmdb/ZooScan_imgs\n",
      "Loading dataset: ZooScan_labels\n",
      "/home/nick/Documents/ws24/lmdb/ZooScan_labels\n",
      "Total data loaded: 13212 images and 13212 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10569/10569 [00:00<00:00, 127248.61it/s]\n",
      "100%|██████████| 2643/2643 [00:00<00:00, 160311.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing and saving datasets to /home/nick/Documents/ws24/out\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_available_memory():\n",
    "    \"\"\"Get available memory and return a safe allocation size for LMDB.\"\"\"\n",
    "    available_memory = psutil.virtual_memory().available\n",
    "    print(f\"Available memory: {available_memory / 1024 / 1024} MB\")\n",
    "    return int(available_memory * 0.75) \n",
    "\n",
    "\n",
    "MAP_SIZE_IMG = get_available_memory()\n",
    "MAP_SIZE_META = int(get_available_memory()*0.1)\n",
    "\n",
    "def load_lmdb_data(lmdb_path):\n",
    "    \"\"\"\n",
    "    Loads data from an LMDB file and returns it as a list of (key, value) pairs.\n",
    "    \"\"\"\n",
    "    env = lmdb.open(lmdb_path, readonly=True)\n",
    "    data = []\n",
    "    with env.begin() as txn:\n",
    "        cursor = txn.cursor()\n",
    "        for key, value in cursor:\n",
    "            data.append((key, value))\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_lmdb_data(lmdb_path_img, lmdb_path_label, img_data, label_data):\n",
    "    \"\"\"\n",
    "    Saves images and labels to LMDB, no decoding and reencoding.\n",
    "    \"\"\"\n",
    "    env_imgs = lmdb.open(lmdb_path_img, map_size=MAP_SIZE_IMG)\n",
    "    env_labels = lmdb.open(lmdb_path_label, map_size=MAP_SIZE_META)\n",
    "        \n",
    "    with (\n",
    "        env_imgs.begin(write=True) as txn_imgs,\n",
    "        env_labels.begin(write=True) as txn_labels,\n",
    "    ):\n",
    "        # Iterate through img_data and label_data, assuming each contains (key, data)\n",
    "        for (img_key, img_encoded), (label_key, label) in tqdm(zip(img_data, label_data), total=len(img_data)):\n",
    "            # Ensure keys match (img_key should be the same in both img_data and label_data)\n",
    "            if img_key != label_key:\n",
    "                print(f\"Warning: Mismatched keys! img_key: {img_key}, label_key: {label_key}\")\n",
    "                continue  # Skip if keys don't match\n",
    "\n",
    "            txn_imgs.put(img_key, img_encoded)  # Save the already-encoded image\n",
    "            txn_labels.put(label_key, label)  # Save the label as bytes\n",
    " \n",
    "    env_imgs.close()\n",
    "    env_labels.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_all_datasets(main_folder):\n",
    "    \"\"\"\n",
    "    Load all datasets in the given folder and return combined image and label data.\n",
    "    \"\"\"\n",
    "    img_data = []\n",
    "    label_data = []\n",
    "    \n",
    "    for dataset in os.listdir(main_folder):\n",
    "        print(f\"Loading dataset: {dataset}\")\n",
    "        dataset_path = os.path.join(main_folder, dataset)\n",
    "        print(dataset_path)\n",
    "        if dataset_path.endswith(\"_imgs\"):\n",
    "            img_data.extend(load_lmdb_data(dataset_path))\n",
    "        elif dataset_path.endswith(\"_labels\"):\n",
    "            label_data.extend(load_lmdb_data(dataset_path))\n",
    "        else:\n",
    "            print(f\"Skipping {dataset_path}\")\n",
    "            print(\"we are fucked if this contains a valid path\")\n",
    "                \n",
    "    return img_data, label_data\n",
    "\n",
    "def split_and_save_data(main_folder, output_folder, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Loads all datasets, splits the data into train and test, and saves them in the output folder.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load all datasets\n",
    "    img_data, label_data = load_all_datasets(main_folder)\n",
    "    \n",
    "    print(f\"Total data loaded: {len(img_data)} images and {len(label_data)} labels.\")\n",
    "\n",
    "    # Split dataset into train and test\n",
    "    train_imgs, test_imgs = train_test_split(img_data, test_size=test_size,shuffle=True, random_state=43)\n",
    "    train_labels, test_labels = train_test_split(label_data, test_size=test_size,shuffle=True, random_state=43)\n",
    "\n",
    "    # Save the split data to LMDB\n",
    "    save_lmdb_data(os.path.join(output_folder, \"TRAIN_imgs\"), os.path.join(output_folder, \"TRAIN_labels\"), train_imgs, train_labels)\n",
    "    save_lmdb_data(os.path.join(output_folder, \"TEST_imgs\"), os.path.join(output_folder, \"TEST_labels\"), test_imgs, test_labels)\n",
    "\n",
    "    print(f\"Finished processing and saving datasets to {output_folder}\")\n",
    "\n",
    "split_and_save_data(main_folder=\"/home/nick/Documents/ws24/lmdb\", output_folder=\"/home/nick/Documents/ws24/out\", test_size=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
